{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_path = r\"../src\"\n",
    "sys.oath.append(module_path)\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from vis.confusion_matrix import plot_cm\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCMC_Dataset:\n",
    "    version: str\n",
    "    name: str\n",
    "    dx: str\n",
    "    data_source: str\n",
    "    num_recordings: str\n",
    "    transition_matrix: np.ndarray\n",
    "    dataset: str = ''\n",
    "    savedir: Path = Path('./export')\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.dataset = self.name if not self.dataset else self.dataset\n",
    "        self.savedir = Path(savedir) / version\n",
    "        self.tm = np.array(self.transition_matrix) if not isinstance(self.transition_matrix, np.ndarray) else self.transition_matrix\n",
    "        self.experiment_name = f'{self.name}_Dx-{self.dx}_Data-{self.dataset}_Recs-{self.num_recordings}'\n",
    "        self.num_samples = self.tm.sum() if self.num_recordings == 2 else self.tm.sum() // 2\n",
    "\n",
    "    def get_transition_matrix(self, plot=False):\n",
    "        if plot:\n",
    "            self.plot_matrix(self.tm, matrix_type='tm')\n",
    "\n",
    "    def get_transition_matrix_normalized(self, plot=False):\n",
    "        tm_norm = self.tm / self.tm.sum(axis=1, keepdims=True)\n",
    "        if plot:\n",
    "            self.plot_matrix(tm_norm, matrix_type='tm_norm', decimals=3)\n",
    "        return tm_norm\n",
    "\n",
    "    def get_initial_distribution_normalized(self, plot=False):\n",
    "        id_norm = self.tm.sum(axis=0) / self.tm.sum()\n",
    "        if plot:\n",
    "            self.plot_matrix(id_norm[np.newaxis, :], matrix_type='id_norm', decimals=3, ylabel='Initial Distribution')\n",
    "        return id_norm\n",
    "\n",
    "    def _single_chain_run(self, initial_distribution, transition_matrix, N, choices):\n",
    "        counts_single = np.zeros(N, dtype=int)\n",
    "        current_state = np.random.choice(choices, p=initial_distribution)\n",
    "        for n in range(N):\n",
    "            counts_single[n] = current_state\n",
    "            current_state = np.random.choice(choices, p=transition_matrix[current_state])\n",
    "        return counts_single\n",
    "\n",
    "    def run_MCMC(self, R: int, N: int, n_jobs=-1, overwrite=False):\n",
    "        \n",
    "        # path stuff\n",
    "        savedir_mcmc = self.savedir / 'mcmc'\n",
    "        os.makedirs(savedir_mcmc, exist_ok=True)\n",
    "        fp_mcmc = savedir_mcmc / f\"{self.experiment_name}_{R}.pkl\" # adding realizations to name\n",
    "\n",
    "        if fp_mcmc.exists() and not overwrite:\n",
    "            with open(fp_mcmc, 'rb') as f:\n",
    "                mcmc_results = pickle.load(f)\n",
    "                print(f\"Loaded existing MCMC results. {fp_mcmc}\")\n",
    "                return mcmc_results\n",
    "        \n",
    "        initial_distribution = self.get_initial_distribution_normalized()\n",
    "        transition_matrix = self.get_transition_matrix_normalized()\n",
    "        num_choices = transition_matrix.shape[0]\n",
    "        choices = list(range(num_choices))\n",
    "        \n",
    "        parallel_results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(self._single_chain_run)(initial_distribution, transition_matrix, N, choices)\n",
    "            for _ in tqdm(range(R), desc=\"Processing MCMC in parallel\")\n",
    "        )\n",
    "        \n",
    "        mcmc_results = np.array(parallel_results)\n",
    "        with open(fp_mcmc, 'wb') as f:\n",
    "            pickle.dump(mcmc_results, f)\n",
    "        print(\"Saved MCMC results.\")\n",
    "        return mcmc_results\n",
    "    \n",
    "    def get_config_dict(self):\n",
    "        return {\n",
    "            'Experiment': self.experiment_name,\n",
    "            'name': self.name,\n",
    "            'Dx': self.dx,\n",
    "            'num samples': self.num_samples,\n",
    "            'data source': self.data_source,\n",
    "            'dataset': self.dataset,\n",
    "            'recordings (#)': self.num_recordings,\n",
    "        }\n",
    "\n",
    "    def plot_matrix(self, x, events=['-', '+'], ylabel='Test 1', xlabel='Test 2', decimals=0, matrix_type='tm'):\n",
    "\n",
    "        # title\n",
    "        title = f\"{self.name}\"\n",
    "        title += f\"\\n{self.data_source}, {self.num_recordings} rec\" if self.num_recordings == 1 else f\"\\n{self.data_source}, {self.num_recordings} recs\"\n",
    "        title += f\"\\n{self.dx} (n={self.num_samples})\"\n",
    "        \n",
    "        # plot\n",
    "        plot_cm(x, events=events, \n",
    "                marginals=False, decimals=decimals, decimals_marg=3,\n",
    "                title=title, xlabel=xlabel, ylabel=ylabel, \n",
    "                figsize=(1.5, 1.5), fontsize=6)\n",
    "        \n",
    "        # save plot\n",
    "        savedir = self.savedir / matrix_type\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        plt.savefig(savedir / f\"{self.experiment_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    \n",
    "    def plot_histogram(self, data, x, hue=None, hue_order=None, binwidth=1, kde=True, kde_kws={'bw_adjust': 8}):\n",
    "        \n",
    "        # helpers\n",
    "        title = f\"{self.name}\\n{self.data_source}, {self.num_recordings} rec(s)\\n{self.dx} (n={self.num_samples})\"\n",
    "        kwargs = {'bins': range(0, 2)} if len(data[x].unique()) == 1 else {'binwidth': 1}\n",
    "        savedir = self.savedir / 'mcmc_hist'\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(nrows=1, figsize=(3.5, 3))\n",
    "        sns.histplot(data, x=x, hue=hue, hue_order=hue_order, kde=kde, kde_kws=kde_kws, ax=ax, **kwargs)\n",
    "        ax.set_title(title)\n",
    "        # ax.set_xlim([0, nights])\n",
    "        # save\n",
    "        fig.savefig(savedir / f\"{self.experiment_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    # Single night - stanford\n",
    "    # ----------------\n",
    "    # PSG only\n",
    "    # {'name': 'NT1 detector - PSG', 'dx': 'NT1', 'dataset': 'Stanford - test', 'data_source': 'nPSG', 'num_recordings': 1, 'transition_matrix': [[37, 280], [37, 280]]},\n",
    "    # {'name': 'NT1 detector - PSG', 'dx': 'Con', 'dataset': 'Stanford - test', 'data_source': 'nPSG', 'num_recordings': 1, 'transition_matrix': [[316, 1], [316, 1]]},\n",
    "    # Wearable - simulated\n",
    "    #{'name': 'Wearable simulated', 'dx': 'NT1', 'dataset': 'Stanford - test', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[153, 164], [153, 164]]},\n",
    "    #{'name': 'Wearable simulated', 'dx': 'Con', 'dataset': 'Stanford - test', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[312, 5], [312, 5]]},\n",
    "    \n",
    "    # Single night - Stanford All\n",
    "    {'name': 'Wearable simulated', 'dx': 'NT1', 'dataset': 'first night (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[61, 90], [61, 90]]},\n",
    "    {'name': 'Wearable simulated', 'dx': 'Con', 'dataset': 'first night (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[4854, 48], [4854, 48]]},\n",
    "    {'name': 'SOREMP positive', 'dx': 'NT1', 'dataset': 'first night (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[62, 89], [62, 89]]},\n",
    "    {'name': 'SOREMP positive', 'dx': 'Con', 'dataset': 'first night (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[4820, 82], [4820, 82]]},\n",
    "    \n",
    "    # Dual night - all\n",
    "    {'name': 'Wearable simulated', 'dx': 'NT1', 'dataset': 'dual nights (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 2, 'transition_matrix': [[13, 6], [1, 8]]},\n",
    "    {'name': 'Wearable simulated', 'dx': 'Con', 'dataset': 'dual nights (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 2, 'transition_matrix': [[4632, 55], [41, 4]]},\n",
    "    {'name': 'SOREMP positive', 'dx': 'NT1', 'dataset': 'dual nights (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 2, 'transition_matrix': [[16, 3], [4, 5]]},\n",
    "    {'name': 'SOREMP positive', 'dx': 'Con', 'dataset': 'dual nights (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 2, 'transition_matrix': [[4580, 72], [76, 4]]},\n",
    "    \n",
    "    # Dual nights - colapsed\n",
    "    {'name': 'Multi-feature', 'dx': 'NT1', 'dataset': 'dual nights - colapsed (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[19, 9], [19, 9]]},\n",
    "    {'name': 'Multi-feature', 'dx': 'Con', 'dataset': 'dual nights - colapsed (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[4687, 45], [4687, 45]]},\n",
    "    {'name': 'SOREMP positive', 'dx': 'NT1', 'dataset': 'dual nights - colapsed (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[19, 9], [19, 9]]},\n",
    "    {'name': 'SOREMP positive', 'dx': 'Con', 'dataset': 'dual nights - colapsed (test)', 'data_source': 'nPSG - hypnogram', 'num_recordings': 1, 'transition_matrix': [[4652, 80], [4652, 80]]},\n",
    "    \n",
    "\n",
    "    # MSLT\n",
    "    # ----------------\n",
    "    # Torstensen et al. (2023)\n",
    "    {'name': 'Torstensen et al. (2023)', 'dx': 'NT1', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[6, 3], [3, 13]]}, \n",
    "    {'name': 'Torstensen et al. (2023)', 'dx': 'DoH', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[74, 4], [15, 7]]}, \n",
    "    # Lopez et al. (2017)\n",
    "    {'name': 'Lopez et al. (2017)', 'dx': 'NT1', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[4, 2], [3, 13]]}, \n",
    "    {'name': 'Lopez et al. (2017)', 'dx': 'DoH', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[47, 11], [9, 8]]}, \n",
    "    # Ruoff et al. (2018)\n",
    "    {'name': 'Ruoff et al. (2018)', 'dx': 'NT1', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[0, 6], [3, 31]]},\n",
    "    {'name': 'Ruoff et al. (2018)', 'dx': 'NT2', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[0, 20], [12, 7]]},\n",
    "    {'name': 'Ruoff et al. (2018)', 'dx': 'Con', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[0, 2], [12, 1]]},\n",
    "    # Trotti et al. (2013)\n",
    "    {'name': 'Trotti et al. (2013)', 'dx': 'DoH', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[19, 2], [10, 5]]},\n",
    "    # MSLT combined\n",
    "    {'name': 'MSLT combined', 'dx': 'NT1', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[10, 11], [9, 47]]},\n",
    "    {'name': 'MSLT combined', 'dx': 'DoH', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[140, 37], [46, 27]]},\n",
    "    {'name': 'MSLT combined', 'dx': 'Con', 'data_source': 'MSLT', 'num_recordings': 2, 'transition_matrix': [[0, 2], [12, 1]]},\n",
    "\n",
    "    # Simulated matrices for stable/unstable cases\n",
    "    {'name': 'Phenotype - Stable positive - 0.9', 'dx': 'NT1', 'data_source': 'simulated', 'num_recordings': 2, 'transition_matrix': [[1, 9], [9, 81]]}, # \n",
    "    {'name': 'Phenotype - Stable negative - 0.9', 'dx': 'NT1', 'data_source': 'simulated', 'num_recordings': 2, 'transition_matrix': [[81, 9], [9, 1]]},\n",
    "    {'name': 'Phenotype - Unstable NT1 - 0.9', 'dx': 'NT1', 'data_source': 'simulated', 'num_recordings': 2, 'transition_matrix': [[50, 50], [50, 50]]},\n",
    "\n",
    "    #{'name': 'Phenotype - Stable positive - 0.8', 'dx': 'NT1', 'data_source': 'simulated', 'num_recordings': 2, 'transition_matrix': [[4, 16], [16, 64]]},\n",
    "    #{'name': 'Phenotype - Stable negative - 0.8', 'dx': 'NT1', 'data_source': 'simulated', 'num_recordings': 2, 'transition_matrix': [[64, 16], [16, 4]]},\n",
    "    #{'name': 'Phenotype - Unstable NT1 - 0.8', 'dx': 'NT1', 'data_source': 'simulated', 'num_recordings': 2, 'transition_matrix': [[50, 50], [50, 50]]},\n",
    "]\n",
    "\n",
    "# parameters\n",
    "plot = True\n",
    "realisations = 100000\n",
    "nights = 14\n",
    "# preallocation\n",
    "dataset_dict, dataset_list = {}, []\n",
    "\n",
    "for n, dataset in enumerate(datasets):\n",
    "        \n",
    "    ds = MCMC_Dataset(version=\"ver1\", **dataset)\n",
    "\n",
    "    # plot matrices\n",
    "    # id = ds.get_initial_distribution_normalized(plot=plot)\n",
    "    tm = ds.get_transition_matrix(plot=plot)\n",
    "    tm_norm = ds.get_transition_matrix_normalized(plot=plot)\n",
    "\n",
    "    # run mcmc\n",
    "    x_mcmc = ds.run_MCMC(R=realisations, N=nights)\n",
    "\n",
    "    # marginalize over nights\n",
    "    x_mcmc_marg = x_mcmc.sum(axis=1)\n",
    "    df = pd.DataFrame(x_mcmc_marg, columns=[\"positive nights (n)\"])\n",
    "    \n",
    "    # plot histogram\n",
    "    ds.plot_histogram(df, x='positive nights (n)')\n",
    "\n",
    "    # append datasets to show\n",
    "    dataset_list.append(ds.get_config_dict())\n",
    "    dataset_dict[n] = ds\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dx",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num samples",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "data source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recordings (#)",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dc86fabf-01f5-4b57-90d2-7efe8b8c5917",
       "rows": [
        [
         "0",
         "Wearable simulated_Dx-NT1_Data-first night (test)_Recs-1",
         "Wearable simulated",
         "NT1",
         "151",
         "nPSG - hypnogram",
         "first night (test)",
         "1"
        ],
        [
         "1",
         "Wearable simulated_Dx-Con_Data-first night (test)_Recs-1",
         "Wearable simulated",
         "Con",
         "4902",
         "nPSG - hypnogram",
         "first night (test)",
         "1"
        ],
        [
         "2",
         "SOREMP positive_Dx-NT1_Data-first night (test)_Recs-1",
         "SOREMP positive",
         "NT1",
         "151",
         "nPSG - hypnogram",
         "first night (test)",
         "1"
        ],
        [
         "3",
         "SOREMP positive_Dx-Con_Data-first night (test)_Recs-1",
         "SOREMP positive",
         "Con",
         "4902",
         "nPSG - hypnogram",
         "first night (test)",
         "1"
        ],
        [
         "4",
         "Wearable simulated_Dx-NT1_Data-dual nights (test)_Recs-2",
         "Wearable simulated",
         "NT1",
         "28",
         "nPSG - hypnogram",
         "dual nights (test)",
         "2"
        ],
        [
         "5",
         "Wearable simulated_Dx-Con_Data-dual nights (test)_Recs-2",
         "Wearable simulated",
         "Con",
         "4732",
         "nPSG - hypnogram",
         "dual nights (test)",
         "2"
        ],
        [
         "6",
         "SOREMP positive_Dx-NT1_Data-dual nights (test)_Recs-2",
         "SOREMP positive",
         "NT1",
         "28",
         "nPSG - hypnogram",
         "dual nights (test)",
         "2"
        ],
        [
         "7",
         "SOREMP positive_Dx-Con_Data-dual nights (test)_Recs-2",
         "SOREMP positive",
         "Con",
         "4732",
         "nPSG - hypnogram",
         "dual nights (test)",
         "2"
        ],
        [
         "8",
         "Multi-feature_Dx-NT1_Data-dual nights - colapsed (test)_Recs-1",
         "Multi-feature",
         "NT1",
         "28",
         "nPSG - hypnogram",
         "dual nights - colapsed (test)",
         "1"
        ],
        [
         "9",
         "Multi-feature_Dx-Con_Data-dual nights - colapsed (test)_Recs-1",
         "Multi-feature",
         "Con",
         "4732",
         "nPSG - hypnogram",
         "dual nights - colapsed (test)",
         "1"
        ],
        [
         "10",
         "SOREMP positive_Dx-NT1_Data-dual nights - colapsed (test)_Recs-1",
         "SOREMP positive",
         "NT1",
         "28",
         "nPSG - hypnogram",
         "dual nights - colapsed (test)",
         "1"
        ],
        [
         "11",
         "SOREMP positive_Dx-Con_Data-dual nights - colapsed (test)_Recs-1",
         "SOREMP positive",
         "Con",
         "4732",
         "nPSG - hypnogram",
         "dual nights - colapsed (test)",
         "1"
        ],
        [
         "12",
         "Torstensen et al. (2023)_Dx-NT1_Data-Torstensen et al. (2023)_Recs-2",
         "Torstensen et al. (2023)",
         "NT1",
         "25",
         "MSLT",
         "Torstensen et al. (2023)",
         "2"
        ],
        [
         "13",
         "Torstensen et al. (2023)_Dx-DoH_Data-Torstensen et al. (2023)_Recs-2",
         "Torstensen et al. (2023)",
         "DoH",
         "100",
         "MSLT",
         "Torstensen et al. (2023)",
         "2"
        ],
        [
         "14",
         "Lopez et al. (2017)_Dx-NT1_Data-Lopez et al. (2017)_Recs-2",
         "Lopez et al. (2017)",
         "NT1",
         "22",
         "MSLT",
         "Lopez et al. (2017)",
         "2"
        ],
        [
         "15",
         "Lopez et al. (2017)_Dx-DoH_Data-Lopez et al. (2017)_Recs-2",
         "Lopez et al. (2017)",
         "DoH",
         "75",
         "MSLT",
         "Lopez et al. (2017)",
         "2"
        ],
        [
         "16",
         "Ruoff et al. (2018)_Dx-NT1_Data-Ruoff et al. (2018)_Recs-2",
         "Ruoff et al. (2018)",
         "NT1",
         "40",
         "MSLT",
         "Ruoff et al. (2018)",
         "2"
        ],
        [
         "17",
         "Ruoff et al. (2018)_Dx-NT2_Data-Ruoff et al. (2018)_Recs-2",
         "Ruoff et al. (2018)",
         "NT2",
         "39",
         "MSLT",
         "Ruoff et al. (2018)",
         "2"
        ],
        [
         "18",
         "Ruoff et al. (2018)_Dx-Con_Data-Ruoff et al. (2018)_Recs-2",
         "Ruoff et al. (2018)",
         "Con",
         "15",
         "MSLT",
         "Ruoff et al. (2018)",
         "2"
        ],
        [
         "19",
         "Trotti et al. (2013)_Dx-DoH_Data-Trotti et al. (2013)_Recs-2",
         "Trotti et al. (2013)",
         "DoH",
         "36",
         "MSLT",
         "Trotti et al. (2013)",
         "2"
        ],
        [
         "20",
         "MSLT combined_Dx-NT1_Data-MSLT combined_Recs-2",
         "MSLT combined",
         "NT1",
         "77",
         "MSLT",
         "MSLT combined",
         "2"
        ],
        [
         "21",
         "MSLT combined_Dx-DoH_Data-MSLT combined_Recs-2",
         "MSLT combined",
         "DoH",
         "250",
         "MSLT",
         "MSLT combined",
         "2"
        ],
        [
         "22",
         "MSLT combined_Dx-Con_Data-MSLT combined_Recs-2",
         "MSLT combined",
         "Con",
         "15",
         "MSLT",
         "MSLT combined",
         "2"
        ],
        [
         "23",
         "Phenotype - Stable positive - 0.9_Dx-NT1_Data-Phenotype - Stable positive - 0.9_Recs-2",
         "Phenotype - Stable positive - 0.9",
         "NT1",
         "100",
         "simulated",
         "Phenotype - Stable positive - 0.9",
         "2"
        ],
        [
         "24",
         "Phenotype - Stable negative - 0.9_Dx-NT1_Data-Phenotype - Stable negative - 0.9_Recs-2",
         "Phenotype - Stable negative - 0.9",
         "NT1",
         "100",
         "simulated",
         "Phenotype - Stable negative - 0.9",
         "2"
        ],
        [
         "25",
         "Phenotype - Unstable NT1 - 0.9_Dx-NT1_Data-Phenotype - Unstable NT1 - 0.9_Recs-2",
         "Phenotype - Unstable NT1 - 0.9",
         "NT1",
         "200",
         "simulated",
         "Phenotype - Unstable NT1 - 0.9",
         "2"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 26
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>name</th>\n",
       "      <th>Dx</th>\n",
       "      <th>num samples</th>\n",
       "      <th>data source</th>\n",
       "      <th>dataset</th>\n",
       "      <th>recordings (#)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wearable simulated_Dx-NT1_Data-first night (te...</td>\n",
       "      <td>Wearable simulated</td>\n",
       "      <td>NT1</td>\n",
       "      <td>151</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>first night (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wearable simulated_Dx-Con_Data-first night (te...</td>\n",
       "      <td>Wearable simulated</td>\n",
       "      <td>Con</td>\n",
       "      <td>4902</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>first night (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOREMP positive_Dx-NT1_Data-first night (test)...</td>\n",
       "      <td>SOREMP positive</td>\n",
       "      <td>NT1</td>\n",
       "      <td>151</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>first night (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOREMP positive_Dx-Con_Data-first night (test)...</td>\n",
       "      <td>SOREMP positive</td>\n",
       "      <td>Con</td>\n",
       "      <td>4902</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>first night (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wearable simulated_Dx-NT1_Data-dual nights (te...</td>\n",
       "      <td>Wearable simulated</td>\n",
       "      <td>NT1</td>\n",
       "      <td>28</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights (test)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wearable simulated_Dx-Con_Data-dual nights (te...</td>\n",
       "      <td>Wearable simulated</td>\n",
       "      <td>Con</td>\n",
       "      <td>4732</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights (test)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOREMP positive_Dx-NT1_Data-dual nights (test)...</td>\n",
       "      <td>SOREMP positive</td>\n",
       "      <td>NT1</td>\n",
       "      <td>28</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights (test)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SOREMP positive_Dx-Con_Data-dual nights (test)...</td>\n",
       "      <td>SOREMP positive</td>\n",
       "      <td>Con</td>\n",
       "      <td>4732</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights (test)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multi-feature_Dx-NT1_Data-dual nights - colaps...</td>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>NT1</td>\n",
       "      <td>28</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights - colapsed (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multi-feature_Dx-Con_Data-dual nights - colaps...</td>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>Con</td>\n",
       "      <td>4732</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights - colapsed (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SOREMP positive_Dx-NT1_Data-dual nights - cola...</td>\n",
       "      <td>SOREMP positive</td>\n",
       "      <td>NT1</td>\n",
       "      <td>28</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights - colapsed (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SOREMP positive_Dx-Con_Data-dual nights - cola...</td>\n",
       "      <td>SOREMP positive</td>\n",
       "      <td>Con</td>\n",
       "      <td>4732</td>\n",
       "      <td>nPSG - hypnogram</td>\n",
       "      <td>dual nights - colapsed (test)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Torstensen et al. (2023)_Dx-NT1_Data-Torstense...</td>\n",
       "      <td>Torstensen et al. (2023)</td>\n",
       "      <td>NT1</td>\n",
       "      <td>25</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Torstensen et al. (2023)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Torstensen et al. (2023)_Dx-DoH_Data-Torstense...</td>\n",
       "      <td>Torstensen et al. (2023)</td>\n",
       "      <td>DoH</td>\n",
       "      <td>100</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Torstensen et al. (2023)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lopez et al. (2017)_Dx-NT1_Data-Lopez et al. (...</td>\n",
       "      <td>Lopez et al. (2017)</td>\n",
       "      <td>NT1</td>\n",
       "      <td>22</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Lopez et al. (2017)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lopez et al. (2017)_Dx-DoH_Data-Lopez et al. (...</td>\n",
       "      <td>Lopez et al. (2017)</td>\n",
       "      <td>DoH</td>\n",
       "      <td>75</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Lopez et al. (2017)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ruoff et al. (2018)_Dx-NT1_Data-Ruoff et al. (...</td>\n",
       "      <td>Ruoff et al. (2018)</td>\n",
       "      <td>NT1</td>\n",
       "      <td>40</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Ruoff et al. (2018)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ruoff et al. (2018)_Dx-NT2_Data-Ruoff et al. (...</td>\n",
       "      <td>Ruoff et al. (2018)</td>\n",
       "      <td>NT2</td>\n",
       "      <td>39</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Ruoff et al. (2018)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruoff et al. (2018)_Dx-Con_Data-Ruoff et al. (...</td>\n",
       "      <td>Ruoff et al. (2018)</td>\n",
       "      <td>Con</td>\n",
       "      <td>15</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Ruoff et al. (2018)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Trotti et al. (2013)_Dx-DoH_Data-Trotti et al....</td>\n",
       "      <td>Trotti et al. (2013)</td>\n",
       "      <td>DoH</td>\n",
       "      <td>36</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>Trotti et al. (2013)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MSLT combined_Dx-NT1_Data-MSLT combined_Recs-2</td>\n",
       "      <td>MSLT combined</td>\n",
       "      <td>NT1</td>\n",
       "      <td>77</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>MSLT combined</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MSLT combined_Dx-DoH_Data-MSLT combined_Recs-2</td>\n",
       "      <td>MSLT combined</td>\n",
       "      <td>DoH</td>\n",
       "      <td>250</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>MSLT combined</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MSLT combined_Dx-Con_Data-MSLT combined_Recs-2</td>\n",
       "      <td>MSLT combined</td>\n",
       "      <td>Con</td>\n",
       "      <td>15</td>\n",
       "      <td>MSLT</td>\n",
       "      <td>MSLT combined</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Phenotype - Stable positive - 0.9_Dx-NT1_Data-...</td>\n",
       "      <td>Phenotype - Stable positive - 0.9</td>\n",
       "      <td>NT1</td>\n",
       "      <td>100</td>\n",
       "      <td>simulated</td>\n",
       "      <td>Phenotype - Stable positive - 0.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Phenotype - Stable negative - 0.9_Dx-NT1_Data-...</td>\n",
       "      <td>Phenotype - Stable negative - 0.9</td>\n",
       "      <td>NT1</td>\n",
       "      <td>100</td>\n",
       "      <td>simulated</td>\n",
       "      <td>Phenotype - Stable negative - 0.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Phenotype - Unstable NT1 - 0.9_Dx-NT1_Data-Phe...</td>\n",
       "      <td>Phenotype - Unstable NT1 - 0.9</td>\n",
       "      <td>NT1</td>\n",
       "      <td>200</td>\n",
       "      <td>simulated</td>\n",
       "      <td>Phenotype - Unstable NT1 - 0.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Experiment  \\\n",
       "0   Wearable simulated_Dx-NT1_Data-first night (te...   \n",
       "1   Wearable simulated_Dx-Con_Data-first night (te...   \n",
       "2   SOREMP positive_Dx-NT1_Data-first night (test)...   \n",
       "3   SOREMP positive_Dx-Con_Data-first night (test)...   \n",
       "4   Wearable simulated_Dx-NT1_Data-dual nights (te...   \n",
       "5   Wearable simulated_Dx-Con_Data-dual nights (te...   \n",
       "6   SOREMP positive_Dx-NT1_Data-dual nights (test)...   \n",
       "7   SOREMP positive_Dx-Con_Data-dual nights (test)...   \n",
       "8   Multi-feature_Dx-NT1_Data-dual nights - colaps...   \n",
       "9   Multi-feature_Dx-Con_Data-dual nights - colaps...   \n",
       "10  SOREMP positive_Dx-NT1_Data-dual nights - cola...   \n",
       "11  SOREMP positive_Dx-Con_Data-dual nights - cola...   \n",
       "12  Torstensen et al. (2023)_Dx-NT1_Data-Torstense...   \n",
       "13  Torstensen et al. (2023)_Dx-DoH_Data-Torstense...   \n",
       "14  Lopez et al. (2017)_Dx-NT1_Data-Lopez et al. (...   \n",
       "15  Lopez et al. (2017)_Dx-DoH_Data-Lopez et al. (...   \n",
       "16  Ruoff et al. (2018)_Dx-NT1_Data-Ruoff et al. (...   \n",
       "17  Ruoff et al. (2018)_Dx-NT2_Data-Ruoff et al. (...   \n",
       "18  Ruoff et al. (2018)_Dx-Con_Data-Ruoff et al. (...   \n",
       "19  Trotti et al. (2013)_Dx-DoH_Data-Trotti et al....   \n",
       "20     MSLT combined_Dx-NT1_Data-MSLT combined_Recs-2   \n",
       "21     MSLT combined_Dx-DoH_Data-MSLT combined_Recs-2   \n",
       "22     MSLT combined_Dx-Con_Data-MSLT combined_Recs-2   \n",
       "23  Phenotype - Stable positive - 0.9_Dx-NT1_Data-...   \n",
       "24  Phenotype - Stable negative - 0.9_Dx-NT1_Data-...   \n",
       "25  Phenotype - Unstable NT1 - 0.9_Dx-NT1_Data-Phe...   \n",
       "\n",
       "                                 name   Dx  num samples       data source  \\\n",
       "0                  Wearable simulated  NT1          151  nPSG - hypnogram   \n",
       "1                  Wearable simulated  Con         4902  nPSG - hypnogram   \n",
       "2                     SOREMP positive  NT1          151  nPSG - hypnogram   \n",
       "3                     SOREMP positive  Con         4902  nPSG - hypnogram   \n",
       "4                  Wearable simulated  NT1           28  nPSG - hypnogram   \n",
       "5                  Wearable simulated  Con         4732  nPSG - hypnogram   \n",
       "6                     SOREMP positive  NT1           28  nPSG - hypnogram   \n",
       "7                     SOREMP positive  Con         4732  nPSG - hypnogram   \n",
       "8                       Multi-feature  NT1           28  nPSG - hypnogram   \n",
       "9                       Multi-feature  Con         4732  nPSG - hypnogram   \n",
       "10                    SOREMP positive  NT1           28  nPSG - hypnogram   \n",
       "11                    SOREMP positive  Con         4732  nPSG - hypnogram   \n",
       "12           Torstensen et al. (2023)  NT1           25              MSLT   \n",
       "13           Torstensen et al. (2023)  DoH          100              MSLT   \n",
       "14                Lopez et al. (2017)  NT1           22              MSLT   \n",
       "15                Lopez et al. (2017)  DoH           75              MSLT   \n",
       "16                Ruoff et al. (2018)  NT1           40              MSLT   \n",
       "17                Ruoff et al. (2018)  NT2           39              MSLT   \n",
       "18                Ruoff et al. (2018)  Con           15              MSLT   \n",
       "19               Trotti et al. (2013)  DoH           36              MSLT   \n",
       "20                      MSLT combined  NT1           77              MSLT   \n",
       "21                      MSLT combined  DoH          250              MSLT   \n",
       "22                      MSLT combined  Con           15              MSLT   \n",
       "23  Phenotype - Stable positive - 0.9  NT1          100         simulated   \n",
       "24  Phenotype - Stable negative - 0.9  NT1          100         simulated   \n",
       "25     Phenotype - Unstable NT1 - 0.9  NT1          200         simulated   \n",
       "\n",
       "                              dataset  recordings (#)  \n",
       "0                  first night (test)               1  \n",
       "1                  first night (test)               1  \n",
       "2                  first night (test)               1  \n",
       "3                  first night (test)               1  \n",
       "4                  dual nights (test)               2  \n",
       "5                  dual nights (test)               2  \n",
       "6                  dual nights (test)               2  \n",
       "7                  dual nights (test)               2  \n",
       "8       dual nights - colapsed (test)               1  \n",
       "9       dual nights - colapsed (test)               1  \n",
       "10      dual nights - colapsed (test)               1  \n",
       "11      dual nights - colapsed (test)               1  \n",
       "12           Torstensen et al. (2023)               2  \n",
       "13           Torstensen et al. (2023)               2  \n",
       "14                Lopez et al. (2017)               2  \n",
       "15                Lopez et al. (2017)               2  \n",
       "16                Ruoff et al. (2018)               2  \n",
       "17                Ruoff et al. (2018)               2  \n",
       "18                Ruoff et al. (2018)               2  \n",
       "19               Trotti et al. (2013)               2  \n",
       "20                      MSLT combined               2  \n",
       "21                      MSLT combined               2  \n",
       "22                      MSLT combined               2  \n",
       "23  Phenotype - Stable positive - 0.9               2  \n",
       "24  Phenotype - Stable negative - 0.9               2  \n",
       "25     Phenotype - Unstable NT1 - 0.9               2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_list).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datasets = [\n",
    "    \n",
    "    # Multi-feature. 2 Nights. NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'Multi-feature - 2 nights',\n",
    "            'approach': 'Multi-feature',\n",
    "            'dependence': 'dependent',\n",
    "            'nights': 2,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[4]}, # NT1 (n=36) - 994-0001, 861-2001 - combined\n",
    "            {'dataset': dataset_dict[5]}, # Con (n=4732) - NSRR, 994-0001, 861-2001 - combined\n",
    "            # TODO - we could add clinical trial data with control data\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "    # Multi-feature. 1 Night of dual night data. NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'Multi-feature - 1 night (Colapsed)',\n",
    "            'approach': 'Multi-feature',\n",
    "            'dependence': 'independent',\n",
    "            'nights': 1,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '994-1501', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[8]}, # NT1 (n=36) - 994-0001, 861-2001 - combined\n",
    "            {'dataset': dataset_dict[9]}, # Con (n=4732) - NSRR, 994-0001, 861-2001 - combined\n",
    "            # TODO - we could add clinical trial data with control data\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "    # Multi-feature. 1 Night of all test samples. NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'Multi-feature - 1 night',\n",
    "            'approach': 'Multi-feature',\n",
    "            'dependence': 'independent',\n",
    "            'nights': 1,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '994-1501', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[0]}, # NT1 (n=311) - multi-HC, 994-0001, 861-2001 - combined\n",
    "            {'dataset': dataset_dict[1]}, # Con (n=4939) - multi-HC, NSRR, 994-0001, 861-2001 - combined\n",
    "            # TODO - we could add clinical trial data with control data\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "    # SOREMPs. 2 Night. NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'SOREMP - 2 nights',\n",
    "            'approach': 'SOREMP',\n",
    "            'dependence': 'dependent',\n",
    "            'nights': 2,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '994-1501', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[6]}, # NT1 (n=36) - 994-0001, 861-2001 - combined\n",
    "            {'dataset': dataset_dict[7]}, # Con (n=4732) - NSRR, 994-0001, 861-2001 - combined\n",
    "            # TODO - we could add clinical trial data with control data\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "    # SOREMPs. 1 Night. NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'SOREMP - 1 night (Colapsed)',\n",
    "            'approach': 'SOREMP',\n",
    "            'dependence': 'independent',\n",
    "            'nights': 1,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '994-1501', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[10]}, # NT1 (n=36) - 994-0001, 861-2001 - combined\n",
    "            {'dataset': dataset_dict[11]}, # Con (n=4732) - NSRR, 994-0001, 861-2001 - combined\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "    # SOREMPs. 1 Night. NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'SOREMP - 1 night',\n",
    "            'approach': 'SOREMP',\n",
    "            'dependence': 'independent',\n",
    "            'nights': 1,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: NSRR/Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '994-1501', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[2]}, # NT1 (n=36) - 994-0001, 861-2001 - combined\n",
    "            {'dataset': dataset_dict[3]}, # Con (n=4732) - NSRR, 994-0001, 861-2001 - combined\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "    # PSG based. 1 Night. NT1: (n=317), Con: NSRR/Stanford (n=317) TODO - update this to the entire dataset!!!\n",
    "    # {\n",
    "    #     'keys': {\n",
    "    #         'name': 'PSG-based - 1 night - Stanford test',\n",
    "    #         'approach': 'PSG-based',\n",
    "    #         'nights': 1,\n",
    "    #         'Dxs': ['NT1', 'Con'],\n",
    "    #         'data_source': 'nPSG - hypnogram',\n",
    "    #         'datasets': 'NT1: Stanford test (n=317), Con: Stanford (n=317)',\n",
    "    #         'datasets_ext': ['Stanford - test'],\n",
    "    #     },\n",
    "    #     'datasets': [\n",
    "    #         {'dataset': dataset_dict[0]}, \n",
    "    #         {'dataset': dataset_dict[1]}\n",
    "    #     ]\n",
    "    # }, \n",
    "\n",
    "    # Multi-feature. 1 Night. NT1: (n=317), Con: NSRR/Stanford (n=317) TODO - update this to the entire dataset!!!\n",
    "    # {\n",
    "    #     'keys': {\n",
    "    #         'name': 'Multi-feature - 1 night - Stanford test',\n",
    "    #         'approach': 'SOREMP',\n",
    "    #         'nights': 1,\n",
    "    #         'Dxs': ['NT1', 'Con'],\n",
    "    #         'data_source': 'nPSG - hypnogram',\n",
    "    #         'datasets': 'NT1: Stanford test (n=317), Con: Stanford (n=317)',\n",
    "    #         'datasets_ext': ['Stanford - test'], # 3 first are NT1s. Last is Stanford.\n",
    "    #     },\n",
    "    #     'datasets': [\n",
    "    #         {'dataset': dataset_dict[4]}, \n",
    "    #         {'dataset': dataset_dict[5]}\n",
    "    #     ]\n",
    "    # }, \n",
    "    \n",
    "    # Compare Phenotypes - stable/unstable\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'Multi-feature - phenotypes',\n",
    "            'approach': 'Multi-feature',\n",
    "            'dependence': 'phenotypes',\n",
    "            'nights': 2,\n",
    "            'Dxs': ['NT1', 'Con'],\n",
    "            'data_source': 'nPSG - hypnogram',\n",
    "            'datasets': 'NT1: Clinical Trials combined (n=54), Con: Stanford (n=4853)',\n",
    "            'datasets_ext': ['994-0001', '994-1501', '861-2001', 'Stanford - all'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'R': round(17/36 * realisations), 'dataset': dataset_dict[23]}, # 22/54\n",
    "            {'R': round(10/36 * realisations), 'dataset': dataset_dict[24]}, # 17/54\n",
    "            {'R': round(9/36 * realisations), 'dataset': dataset_dict[25]}, # 15/54\n",
    "            {'dataset': dataset_dict[5]} # control dataset - R will default to realisations if not specified.\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Compare MSLT TODO - makes most sense with DOH\n",
    "    # TODO - add NT2s.!\n",
    "    # TODO - differentiate NT2s from DoH.\n",
    "    {\n",
    "        'keys': {\n",
    "            'name': 'MSLT - 2 night',\n",
    "            'approach': 'MSLT',\n",
    "            'dependence': 'dependent',\n",
    "            'nights': 2,\n",
    "            'Dxs': ['NT1', 'DoH', 'Con'],\n",
    "            'data_source': 'MSLT',\n",
    "            'datasets': 'NT1: MSLT cohorts combined (n=77), DoH: MSLT cohorts combined (n=250), Con: MSLT cohorts combined (n=15)',\n",
    "            'datasets_ext': ['Stanford - test'], # 3 first are NT1s. Last is Stanford.\n",
    "        },\n",
    "        'datasets': [\n",
    "            {'dataset': dataset_dict[20]}, # 77 NT1s \n",
    "            {'dataset': dataset_dict[21]}, # 250 DoH TODO - figure out how to add this!\n",
    "            {'dataset': dataset_dict[22]}, # 15 Con\n",
    "        ]\n",
    "    } \n",
    "    \n",
    "    # TODO Compare Scorings versus Hypnodensity based.    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process multinight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import metrics_dict_array\n",
    "\n",
    "def requirement_fun(x, axis, n_minimum):\n",
    "    \"\"\"Return a boolean array indicating whether the sum along a given axis meets or exceeds n_minimum.\"\"\"\n",
    "    return x.sum(axis=axis) >= n_minimum\n",
    "\n",
    "def compute_metrics(y, p, prevalence, min_PPV=0., min_Re=0.):\n",
    "    \"\"\"Compute sensitivity, specificity, and prevalence-adjusted counts.\"\"\"\n",
    "    SE = metrics_dict_array['recall'](y, p)\n",
    "    SP = metrics_dict_array['specificity'](y, p)\n",
    "\n",
    "    total_samples = len(y)\n",
    "    expected_positives = total_samples * prevalence\n",
    "    expected_negatives = total_samples * (1 - prevalence)\n",
    "\n",
    "    TP = SE * expected_positives\n",
    "    FN = (1 - SE) * expected_positives\n",
    "    FP = (1 - SP) * expected_negatives\n",
    "    TN = SP * expected_negatives\n",
    "\n",
    "    PPV = (SE * prevalence) / (SE * prevalence + (1 - SP) * (1 - prevalence)) if SE > 0 else 0\n",
    "    FP_TP_ratio = FP / TP if TP > 0 else float('inf')\n",
    "    F1_score = 2 * (PPV * SE) / (PPV + SE) if PPV + SE > 0 else 0\n",
    "    F1_score_minPPV = F1_score if (PPV > min_PPV) & (SE > min_Re) else np.nan\n",
    "    Recall_at_minPPV = SE if (PPV > min_PPV) & (SE > min_Re) else np.nan\n",
    "\n",
    "    out = {\n",
    "        'Sensitivity': SE,\n",
    "        'Specificity': SP,\n",
    "        'PPV': PPV,\n",
    "        'FP:TP': FP_TP_ratio,\n",
    "        'F1 score': F1_score,\n",
    "        'F1 score (min. PPV)': F1_score_minPPV,\n",
    "        'Recall_at_minPPV': Recall_at_minPPV,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'TP': TP\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def process_nights(y, p_full, nights, prevalences, min_PPVs, min_REs, n_jobs=-1):\n",
    "    \"\"\"Parallelized function to compute evaluation metrics across nights and prevalence levels.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    def process_combination(n, n_min, prev, min_PPV, min_Re):\n",
    "        \"\"\"Process a single (n, n_min, prev_) combination in parallel.\"\"\"\n",
    "        # subset = np.concatenate((x_con[:, :n+1], x_nt1[:, :n+1]), axis=0)\n",
    "        p_subset = p_full[:, :n+1]\n",
    "        p = requirement_fun(p_subset, axis=1, n_minimum=n_min + 1)\n",
    "        \n",
    "        metrics = compute_metrics(y, p, prev, min_PPV, min_Re)\n",
    "\n",
    "        return {\n",
    "            'Recordings (n)': n + 1,\n",
    "            'Min. required positive (n)': n_min + 1,\n",
    "            'Prevalence': f'1:{int(1/prev)}',\n",
    "            'min PPV': min_PPV,\n",
    "            'min Re': min_Re,\n",
    "            **metrics\n",
    "        }\n",
    "\n",
    "    # Run the parallel computation\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_combination)(n, n_min, prev, min_PPV, min_Re)\n",
    "        for n in nights \n",
    "        for n_min in range(n + 1)\n",
    "        for prev in prevalences\n",
    "        for min_PPV in min_PPVs\n",
    "        for min_Re in min_REs\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data, x, hue=None, hue_order=None, title='', kde=True, kde_kws={'bw_adjust': 8}, savedir='./'):\n",
    "    \n",
    "    # sns.set(style='default')\n",
    "\n",
    "    # helpers\n",
    "    kwargs = {'bins': range(0, 2)} if len(data[x].unique()) == 1 else {'binwidth': 1}\n",
    "    savedir = savedir / 'mcmc_hist_hue'\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(3.5, 3.5))\n",
    "    sns.histplot(\n",
    "        data, \n",
    "        x=x, \n",
    "        hue=hue, \n",
    "        hue_order=hue_order, \n",
    "        stat='probability',\n",
    "        common_norm=False,\n",
    "        multiple='layer',\n",
    "        # discrete=True,\n",
    "        #kde=kde, \n",
    "        #kde_kws=kde_kws, \n",
    "        ax=ax, \n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # bins\n",
    "    bins = np.arange(0, 15, 1)\n",
    "    ax.set_xticks(bins)\n",
    "    ax.set_xticklabels([str(tick) for tick in bins])\n",
    "    ax.set_xlim([0, 14])\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, which='major', axis='both', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "    # titles\n",
    "    ax.set_title(title)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Con', 1: 'NT1', 2: 'DoH'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx2idx = {\n",
    "    'Con': 0,\n",
    "    'NT1': 1,\n",
    "    'DoH': 2\n",
    "}\n",
    "# Sort function using dx2idx\n",
    "def sort_by_dx_order(dx_list):\n",
    "    return sorted(dx_list, key=lambda dx: dx2idx[dx])\n",
    "\n",
    "idx2dx = {item: key for key, item in dx2idx.items()}\n",
    "idx2dx \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "realisations = 100000\n",
    "prevalences = [1 / x for x in [2, 8, 32, 128, 512, 2048]]\n",
    "nights = [0, 2, 4, 6, 9, 13]\n",
    "nights = list(range(14))\n",
    "\n",
    "#prevalences = ['1:128', '1:512', '1:2048']\n",
    "min_PPVs = [2/3, 1/2, 1/3] # Corresponds to: FP:DP = [0.5, 1, 2] # FP:TP ratio\n",
    "min_REs = [1/5, 1/4, 1/3, 1/2]\n",
    "FP_TP_criterias = [1/pre - 1 for pre in min_PPVs]\n",
    "hist_plot = True\n",
    "\n",
    "results = []\n",
    "#for com_datasets in tqdm(combined_datasets, total=len(combined_datasets), desc='Processing'):\n",
    "for com_datasets in combined_datasets: # [:1]:\n",
    "    \n",
    "    # okay\n",
    "    p = np.empty((0, len(nights)))\n",
    "    y = np.empty(0)\n",
    "    \n",
    "    for dataset_dict_ in com_datasets['datasets']:\n",
    "        \n",
    "        # extract object\n",
    "        dataset = dataset_dict_.get('dataset')\n",
    "        R = dataset_dict_.get('R', realisations) \n",
    "        \n",
    "        # extract p and y\n",
    "        p_ = dataset.run_MCMC(realisations, N=nights) \n",
    "        p = np.concatenate((p, p_[:R, :]), axis=0) \n",
    "        y = np.concatenate((y, np.ones(R) * dx2idx[dataset.dx]), axis=0)\n",
    "    \n",
    "    if hist_plot: # plot hisogram\n",
    "        # prep\n",
    "        p_marg = p.sum(axis=1)\n",
    "        df = pd.DataFrame({'Dx': y, 'positive recordings (n)': p_marg})\n",
    "        df['Dx'] = df['Dx'].replace(idx2dx)\n",
    "        \n",
    "        # plot\n",
    "        plot_histogram(data=df, x='positive recordings (n)', hue='Dx', hue_order=sort_by_dx_order(com_datasets['keys'].get('Dxs')),\n",
    "                       title=com_datasets['keys'].get('name'), savedir=savedir)\n",
    "        \n",
    "    # compute metrics\n",
    "    result = process_nights(y=y, p_full=p, nights=nights, prevalences=prevalences, min_PPVs=min_PPVs, min_REs=min_REs)\n",
    "    \n",
    "    # Add extra keys\n",
    "    for r in result:\n",
    "        r.update(com_datasets['keys']) # update - adds in place and returns None\n",
    "\n",
    "    results += result\n",
    "    \n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.shape)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_results.to_csv(savedir, f\"{mcmc_analysis}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: ['Multi-feature - 2 nights' 'Multi-feature - 1 night' 'SOREMP - 2 nights'\n",
      " 'SOREMP - 1 night' 'PSG-based - 1 night - Stanford test'\n",
      " 'Multi-feature - 1 night - Stanford test' 'Multi-feature - phenotypes']\n",
      "\n",
      "Recordings (n): [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Min. required positive (n): [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "Prevalence: ['1:2' '1:8' '1:32' '1:128' '1:512' '1:2048']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['name', 'Recordings (n)', 'Min. required positive (n)', 'Prevalence']\n",
    "for col in cols: \n",
    "    print(f\"{col}: {df_results[col].unique()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of multi-night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# TODO - Figure this out! effect of multi-night:\n",
    "\n",
    "# sim = {'name': 'Wearable simulated - Stanford all - 1 rec', 'NT1_dataset': dataset_dict[6], 'Con_dataset': dataset_dict[7]}\n",
    "sim = {'name': 'Wearable simulated\\n994-0001, 994-1501, 861-2001', 'NT1_dataset': dataset_dict[20], 'Con_dataset': dataset_dict[13]}\n",
    "# dataset\n",
    "ds_nt1, ds_con = sim.get('NT1_dataset'), sim.get('Con_dataset')\n",
    "\n",
    "# run mcmc\n",
    "mcmc_nt1 = ds_nt1.run_MCMC(R=realisations, N=nights) #, overwrite=True)\n",
    "mcmc_con = ds_con.run_MCMC(R=realisations, N=nights) #, overwrite=True)\n",
    "\n",
    "for n in [1, 3, 7, 14]:    \n",
    "    # plot histogram\n",
    "    mcmc_nt1_marg, mcmc_con_marg = mcmc_nt1[:, :n].sum(axis=1), mcmc_con[:, :n].sum(axis=1)\n",
    "    df = pd.DataFrame({ds_nt1.dx: mcmc_nt1_marg, ds_con.dx: mcmc_con_marg}).melt(value_name='positive nights (n)', var_name='Dx')\n",
    "    plot_histogram(df, x='positive nights (n)', hue='Dx', hue_order=[ds_con.dx, ds_nt1.dx], figsize=(5, 4), version=version,\n",
    "                   xlim=(0, n), title=f\"Recordings: {n}\")\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# select data\n",
    "title = 'Wearable simulated\\n994-0001, 994-1501, 861-2001'\n",
    "min_req_nights = 6\n",
    "min_PPV = 1/2\n",
    "prevalence = '1:2048'\n",
    "df_results_ = df_results[(df_results['Min. required positive (n)'] <= min_req_nights) & (df_results['title'] == title) & (df_results['Prevalence'] == prevalence) & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# parameters\n",
    "hue = 'Min. required positive (n)'\n",
    "x = 'Recordings (n)'\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 3.5))\n",
    "\n",
    "# Sensitivity plot\n",
    "sns.pointplot(df_results_, hue=hue, y='Sensitivity', x=x, palette='deep', ax=axes[0], ms=5)\n",
    "axes[0].set_title('Sensitivity')\n",
    "#axes[0].set_xlabel('Number of Days')\n",
    "axes[0].set_ylabel('Sensitivity')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend().remove()\n",
    "\n",
    "# Specificity plot\n",
    "sns.pointplot(df_results_, hue=hue, y='F1 score (min. PPV)', x=x, palette='deep', ax=axes[1], ms=5)\n",
    "axes[1].set_title('F1 score')\n",
    "#axes[1].set_xlabel('Number of Days')\n",
    "axes[1].set_ylabel('F1 score')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend().remove()\n",
    "\n",
    "# FP:TP Ratio plot\n",
    "sns.pointplot(df_results_, hue=hue, y='FP:TP', x=x, palette='deep', ax=axes[2], ms=5)\n",
    "axes[2].set_title('FP:TP ratio')\n",
    "#axes[2].set_xlabel('Number of Days')\n",
    "axes[2].set_ylabel('FP:TP ratio')\n",
    "axes[2].grid(True)\n",
    "axes[2].legend(title=hue, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Customize y-tick labels to actual values\n",
    "# ticks = [epsilon, 0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "ticks = [0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "axes[2].set_yscale('symlog', base=2, linthresh=1)  # Log scale with linear threshold near zero\n",
    "axes[2].set_ylim([0, 2e3])\n",
    "axes[2].set_yticks(ticks)\n",
    "axes[2].set_yticklabels([f'{tick:.2f}' if tick < 1 else f'{tick}' for tick in ticks])  # Format values for readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# select data\n",
    "title = 'Wearable simulated\\nStanford all - 1 rec'\n",
    "min_req_nights = 6\n",
    "min_PPV = 1/2\n",
    "prevalence = '1:2048'\n",
    "df_results_ = df_results[(df_results['Min. required positive (n)'] <= min_req_nights) & (df_results['title'] == title) & (df_results['Prevalence'] == prevalence) & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# parameters\n",
    "hue = 'Min. required positive (n)'\n",
    "x = 'Recordings (n)'\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 3.5))\n",
    "\n",
    "# Sensitivity plot\n",
    "sns.pointplot(df_results_, hue=hue, y='Sensitivity', x=x, palette='deep', ax=axes[0], ms=5)\n",
    "axes[0].set_title('Sensitivity')\n",
    "#axes[0].set_xlabel('Number of Days')\n",
    "axes[0].set_ylabel('Sensitivity')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend().remove()\n",
    "\n",
    "# Specificity plot\n",
    "sns.pointplot(df_results_, hue=hue, y='F1 score (min. PPV)', x=x, palette='deep', ax=axes[1], ms=5)\n",
    "axes[1].set_title('F1 score')\n",
    "#axes[1].set_xlabel('Number of Days')\n",
    "axes[1].set_ylabel('F1 score')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend().remove()\n",
    "\n",
    "# FP:TP Ratio plot\n",
    "sns.pointplot(df_results_, hue=hue, y='FP:TP', x=x, palette='deep', ax=axes[2], ms=5)\n",
    "axes[2].set_title('FP:TP ratio')\n",
    "#axes[2].set_xlabel('Number of Days')\n",
    "axes[2].set_ylabel('FP:TP ratio')\n",
    "axes[2].grid(True)\n",
    "axes[2].legend(title=hue, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Customize y-tick labels to actual values\n",
    "# ticks = [epsilon, 0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "ticks = [0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "axes[2].set_yscale('symlog', base=2, linthresh=1)  # Log scale with linear threshold near zero\n",
    "axes[2].set_ylim([0, 2e3])\n",
    "axes[2].set_yticks(ticks)\n",
    "axes[2].set_yticklabels([f'{tick:.2f}' if tick < 1 else f'{tick}' for tick in ticks])  # Format values for readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data\n",
    "titles = [\n",
    "    'NT1 detector\\nPSG - Stanford test - 1 rec', \n",
    "    'Wearable simulated\\nStanford all - 1 rec'\n",
    "]\n",
    "recordings = 1 \n",
    "df_results_ = df_results[df_results['title'].isin(titles) & (df_results['Recordings (n)'] == recordings)  & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# parameters\n",
    "epsilon = 1e-5\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "sns.pointplot(\n",
    "    df_results_,\n",
    "    x='Prevalence', \n",
    "    y='FP:TP', \n",
    "    hue='title',\n",
    "    markers=['o', 's', 'v', 'd', 'x'], ms=6,\n",
    "    lw=1.5,\n",
    "    ax=ax[0]\n",
    ")\n",
    "\n",
    "# Configurations\n",
    "ax[0].set_ylabel('FP:TP ratio\\n (1/precision - 1)')\n",
    "ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Set y-axis to log scale\n",
    "#ax.set_yscale('symlog', base=2, linthresh=1e-2)  # Log scale with linear threshold near zero\n",
    "ax[0].set_yscale('symlog', base=2, linthresh=1)  # Log scale with linear threshold near zero\n",
    "ax[0].set_ylim([0, 300])\n",
    "\n",
    "# Customize y-tick labels to actual values\n",
    "ticks = [epsilon, 0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "ticks = [0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "ax[0].set_yticks(ticks)\n",
    "ax[0].set_yticklabels([f'{tick:.2f}' if tick < 1 else f'{tick}' for tick in ticks])  # Format values for readability\n",
    "\n",
    "# final\n",
    "ax[0].grid()\n",
    "\n",
    "sns.barplot(df_results_, hue='title', y='Sensitivity', ax=ax[1])\n",
    "ax[1].legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Recordings (n)</th>\n",
       "      <th>Min. required positive (n)</th>\n",
       "      <th>Prevalence</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>FP:TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, Recordings (n), Min. required positive (n), Prevalence, Sensitivity, Specificity, PPV, FP:TP, TN, FP, FN, TP]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[(df_results['Recordings (n)'] == recordings) & (df_results['Min. required positive (n)'] == min_req_nights)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select data\n",
    "titles = [\n",
    "    'NT1 detector\\nPSG - Stanford test - 1 rec',\n",
    "    'Wearable simulated\\nStanford all - 1 rec',\n",
    "    'SOREMP\\nStanford all - 1 rec',\n",
    "    'Wearable simulated\\n994-0001, 994-1501, 861-2001',\n",
    "    'SOREMP\\n994-0001, 994-1501, 861-2001',\n",
    "    #'Wearable simulated\\nclinical trial NT1s vs. Stanford (NSRR) Controls',\n",
    "    #'SOREMP\\nclinical trial NT1s vs. Stanford (NSRR) Controls',\n",
    "    #'MLST\\nMSLT combined NT1s vs. Stanford (NSRR) controls',\n",
    "    #'MSLT\\nNT1s vs. DoH - 2 recs',\n",
    "]\n",
    "min_req_nights = 3\n",
    "recordings = 7\n",
    "min_PPV = 1/2\n",
    "df_results_ = df_results[df_results['title'].isin(titles) & (df_results['Recordings (n)'] == recordings) & (df_results['Min. required positive (n)'] == min_req_nights) & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# parameters\n",
    "epsilon = 1e-5\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "sns.pointplot(\n",
    "    df_results_,\n",
    "    x='Prevalence', \n",
    "    y='FP:TP', \n",
    "    hue='title', \n",
    "    markers=['o', 's', 'v', 'd', 'x'], ms=6,\n",
    "    lw=1.5,\n",
    "    ax=ax[0]\n",
    ")\n",
    "\n",
    "# Configurations\n",
    "ax[0].set_ylabel('FP:TP ratio\\n (1/precision - 1)')\n",
    "ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Set y-axis to log scale\n",
    "#ax.set_yscale('symlog', base=2, linthresh=1e-2)  # Log scale with linear threshold near zero\n",
    "ax[0].set_yscale('symlog', base=2, linthresh=1)  # Log scale with linear threshold near zero\n",
    "ax[0].set_ylim([0, 300])\n",
    "\n",
    "# Customize y-tick labels to actual values\n",
    "ticks = [epsilon, 0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "ticks = [0.1, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "ax[0].set_yticks(ticks)\n",
    "ax[0].set_yticklabels([f'{tick:.2f}' if tick < 1 else f'{tick}' for tick in ticks])  # Format values for readability\n",
    "\n",
    "# final\n",
    "ax[0].grid()\n",
    "\n",
    "sns.barplot(df_results_, hue='title', y='Sensitivity', ax=ax[1])\n",
    "ax[1].legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Recordings (n)</th>\n",
       "      <th>Min. required positive (n)</th>\n",
       "      <th>Prevalence</th>\n",
       "      <th>min PPV</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>FP:TP</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>F1 score (min. PPV)</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NT1 detector\\nPSG - Stanford test - 1 rec</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1:2048</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>199902.343750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>97.623047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>Wearable simulated\\nStanford all - 1 rec</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1:2048</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.87689</td>\n",
       "      <td>0.99909</td>\n",
       "      <td>0.320073</td>\n",
       "      <td>2.124292</td>\n",
       "      <td>0.468968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199720.432617</td>\n",
       "      <td>181.911133</td>\n",
       "      <td>12.022461</td>\n",
       "      <td>85.633789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>SOREMP\\nStanford all - 1 rec</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1:2048</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.79330</td>\n",
       "      <td>0.99993</td>\n",
       "      <td>0.847009</td>\n",
       "      <td>0.180625</td>\n",
       "      <td>0.819275</td>\n",
       "      <td>0.819275</td>\n",
       "      <td>199888.350586</td>\n",
       "      <td>13.993164</td>\n",
       "      <td>20.185547</td>\n",
       "      <td>77.470703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>Wearable simulated\\n994-0001, 994-1501, 861-2001</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1:2048</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.87657</td>\n",
       "      <td>0.99770</td>\n",
       "      <td>0.156960</td>\n",
       "      <td>5.371049</td>\n",
       "      <td>0.266246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199442.568359</td>\n",
       "      <td>459.775391</td>\n",
       "      <td>12.053711</td>\n",
       "      <td>85.602539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>SOREMP\\n994-0001, 994-1501, 861-2001</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1:2048</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.42613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597603</td>\n",
       "      <td>0.597603</td>\n",
       "      <td>199902.343750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.041992</td>\n",
       "      <td>41.614258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  Recordings (n)  \\\n",
       "430          NT1 detector\\nPSG - Stanford test - 1 rec               7   \n",
       "2320          Wearable simulated\\nStanford all - 1 rec               7   \n",
       "4210                      SOREMP\\nStanford all - 1 rec               7   \n",
       "6100  Wearable simulated\\n994-0001, 994-1501, 861-2001               7   \n",
       "7990              SOREMP\\n994-0001, 994-1501, 861-2001               7   \n",
       "\n",
       "      Min. required positive (n) Prevalence  min PPV  Sensitivity  \\\n",
       "430                            3     1:2048      0.5      0.99966   \n",
       "2320                           3     1:2048      0.5      0.87689   \n",
       "4210                           3     1:2048      0.5      0.79330   \n",
       "6100                           3     1:2048      0.5      0.87657   \n",
       "7990                           3     1:2048      0.5      0.42613   \n",
       "\n",
       "      Specificity       PPV     FP:TP  F1 score  F1 score (min. PPV)  \\\n",
       "430       1.00000  1.000000  0.000000  0.999830             0.999830   \n",
       "2320      0.99909  0.320073  2.124292  0.468968                  NaN   \n",
       "4210      0.99993  0.847009  0.180625  0.819275             0.819275   \n",
       "6100      0.99770  0.156960  5.371049  0.266246                  NaN   \n",
       "7990      1.00000  1.000000  0.000000  0.597603             0.597603   \n",
       "\n",
       "                 TN          FP         FN         TP  \n",
       "430   199902.343750    0.000000   0.033203  97.623047  \n",
       "2320  199720.432617  181.911133  12.022461  85.633789  \n",
       "4210  199888.350586   13.993164  20.185547  77.470703  \n",
       "6100  199442.568359  459.775391  12.053711  85.602539  \n",
       "7990  199902.343750    0.000000  56.041992  41.614258  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_[df_results_['Prevalence'] == '1:2048'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# select data\n",
    "title = 'Wearable simulated\\n994-0001, 994-1501, 861-2001'\n",
    "min_req_nights = 6\n",
    "min_PPV = 1/2\n",
    "prevalence = '1:2048'\n",
    "df_results_ = df_results[(df_results['Min. required positive (n)'] <= min_req_nights) & (df_results['title'] == title) & (df_results['Prevalence'] == prevalence) & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# Plot\n",
    "hue = 'Min. required positive (n)'\n",
    "x = 'Recordings (n)'\n",
    "y = 'FP:TP'\n",
    "data = (df_results_.pivot(index=hue, columns=x, values=y))\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(12, 3))\n",
    "sns.heatmap(\n",
    "    data, \n",
    "    annot=True, \n",
    "    fmt=\".1f\", \n",
    "    linewidths=.5, \n",
    "    ax=ax, \n",
    "    vmin=0, \n",
    "    vmax=1000, \n",
    "    norm=LogNorm(vmin=1, vmax=1000), \n",
    "    annot_kws={\"size\": 8}\n",
    ")\n",
    "cb = ax.collections[0].colorbar\n",
    "cb.set_label('FP:TP ratio')\n",
    "\n",
    "# you have prevalence too! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# select data\n",
    "title = 'Wearable simulated\\n994-0001, 994-1501, 861-2001'\n",
    "min_req_nights = 6\n",
    "min_PPV = 1/2\n",
    "prevalence = '1:2048'\n",
    "df_results_ = df_results[(df_results['Min. required positive (n)'] <= min_req_nights) & (df_results['title'] == title) & (df_results['Prevalence'] == prevalence) & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# Plot\n",
    "hue = 'Min. required positive (n)'\n",
    "x = 'Recordings (n)'\n",
    "y = 'F1 score (min. PPV)'\n",
    "data = (df_results_.pivot(index=hue, columns=x, values=y))\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(12, 3))\n",
    "sns.heatmap(\n",
    "    data, \n",
    "    annot=True, \n",
    "    fmt=\".1f\", \n",
    "    linewidths=.5, \n",
    "    ax=ax, \n",
    "    #vmin=0, \n",
    "    #vmax=1, \n",
    "    #norm=LogNorm(vmin=1, vmax=1000), \n",
    "    annot_kws={\"size\": 8}\n",
    ")\n",
    "cb = ax.collections[0].colorbar\n",
    "cb.set_label('F1 score')\n",
    "\n",
    "# you have prevalence too! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# select data\n",
    "title = 'Wearable simulated\\n994-0001, 994-1501, 861-2001'\n",
    "min_req_nights = 3\n",
    "min_PPV = 1/2\n",
    "#prevalence = '1:2048'\n",
    "#min_req_nights = 3\n",
    "df_results_ = df_results[(df_results['Min. required positive (n)'] == min_req_nights) & (df_results['title'] == title) & (df_results['min PPV'] == min_PPV)]\n",
    "\n",
    "# Plot\n",
    "hue = 'Prevalence'\n",
    "x = 'Recordings (n)'\n",
    "y = 'F1 score (min. PPV)'\n",
    "data = (df_results_.pivot(index=hue, columns=x, values=y))\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(12, 3))\n",
    "sns.heatmap(\n",
    "    data, \n",
    "    annot=True, \n",
    "    fmt=\".1f\", \n",
    "    linewidths=.5, \n",
    "    ax=ax, \n",
    "    #vmin=0, \n",
    "    #vmax=1, \n",
    "    #norm=LogNorm(vmin=1, vmax=1000), \n",
    "    annot_kws={\"size\": 8}\n",
    ")\n",
    "cb = ax.collections[0].colorbar\n",
    "cb.set_label('F1 score')\n",
    "\n",
    "# you have prevalence too! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step - what is it?! ?! ?! \n",
    "\n",
    "# try prevalences: \n",
    "prevalences = ['1:128', '1:512', '1:2048']\n",
    "min_precisions = [4/5, 1/2, 1/3]\n",
    "# FP_TP_criterias = [1/pre - 1 for pre in precision]\n",
    "\n",
    "# what do you want the plot to look like: \n",
    "# y = sensitivity, only display sensitivities for valid FP:TP ratios. You enforce a minimum FP:TP ratio first. \n",
    "# cols = prevalence (test for 3 prevalences only)\n",
    "# x = # recordings\n",
    "# hue = titles.\n",
    "\n",
    "# I still need to plot FP:TP ratio on second y axis...\n",
    "# first y-axis is sensitivity, second y-axis is bar-plot of FP:TP ratio.\n",
    "\n",
    "# select data \n",
    "titles = [\n",
    "    #'NT1 detector\\nPSG - Stanford test - 1 rec',\n",
    "    #'Wearable simulated\\nStanford all - 1 rec',\n",
    "    #'SOREMP\\nStanford all - 1 rec',\n",
    "    'Wearable simulated\\n994-0001, 994-1501, 861-2001',\n",
    "    #'SOREMP\\n994-0001, 994-1501, 861-2001',\n",
    "    #'Wearable simulated\\nclinical trial NT1s vs. Stanford (NSRR) Controls',\n",
    "    #'SOREMP\\nclinical trial NT1s vs. Stanford (NSRR) Controls',\n",
    "    #'MLST\\nMSLT combined NT1s vs. Stanford (NSRR) controls',\n",
    "    #'MSLT\\nNT1s vs. DoH - 2 recs'\n",
    "]\n",
    "\n",
    "df_out = []\n",
    "for min_precision in min_precisions: \n",
    "    for title in titles:\n",
    "        for prevalence in prevalences:\n",
    "            for night in nights:\n",
    "                \n",
    "                # select data:\n",
    "                df_ = df_results[\n",
    "                    (df_results['title'] == title) & \n",
    "                    (df_results['Recordings (n)'] == (night + 1)) & \n",
    "                    (df_results['Prevalence'] == prevalence) &\n",
    "                    (df_results['min PPV'] == min_precision)\n",
    "                ]\n",
    "                \n",
    "                # select max 'f1 score (min. PPV)'\n",
    "                #df_ = df_.sort_values(by='F1 score (min. PPV)', ascending=False).head(1)\n",
    "                df_sorted = df_.sort_values(by='F1 score (min. PPV)', ascending=False).head(1)\n",
    "                if not df_sorted.empty:\n",
    "                    df_dict = df_sorted.iloc[0].to_dict()\n",
    "                    if df_dict['F1 score (min. PPV)'] > 0:\n",
    "                        df_out.append(df_dict)\n",
    "                \n",
    "\n",
    "df_selected = pd.DataFrame(df_out)\n",
    "\n",
    "cols = ['title', 'Recordings (n)', 'Min. required positive (n)', 'Prevalence', 'min PPV']\n",
    "for col in cols: \n",
    "    print(f\"{col}: {df_selected[col].unique()}\\n\")\n",
    "print(df_selected.shape)\n",
    "df_selected.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot \n",
    "\n",
    "\n",
    "# select data:\n",
    "# df_selected[df_selected['title'] == 'NT1 detector\\nPSG - Stanford test - 1 rec']\n",
    "x = 'Recordings (n)'\n",
    "cols = 'Prevalence'\n",
    "rows = 'min PPV'\n",
    "y = 'F1 score'\n",
    "hue = 'title'\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(ncols=3, nrows=3, figsize=(12, 9))\n",
    "\n",
    "for i, min_precision in enumerate(min_precisions):\n",
    "    for j, prevalence in enumerate(prevalences):\n",
    "        \n",
    "        # select data:\n",
    "        df_ = df_selected[\n",
    "            (df_selected['Prevalence'] == prevalence) & \n",
    "            (df_selected['min PPV'] == min_precision)\n",
    "        ]\n",
    "        \n",
    "        # plot\n",
    "        sns.pointplot(df_, x=x, y=y, hue=hue, ax=axes[i, j], palette='deep', ms=5, hue_order=titles)\n",
    "\n",
    "        # set titles and labels\n",
    "        axes[i, j].set_title(f\"Prevalence: {prevalence}\\nMax FP:TP ratio: {min_precision:.2f}\")\n",
    "        axes[i, j].set_ylabel('F1 score')\n",
    "        axes[i, j].set_xlabel('Recordings')\n",
    "        axes[i, j].grid(True)\n",
    "        \n",
    "        # remove legends to avoid duplication\n",
    "        axes[i, j].legend().remove()\n",
    "\n",
    "axes[0, 2].legend(title=hue, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot \n",
    "\n",
    "\n",
    "# select data:\n",
    "# df_selected[df_selected['title'] == 'NT1 detector\\nPSG - Stanford test - 1 rec']\n",
    "x = 'Recordings (n)'\n",
    "cols = 'Prevalence'\n",
    "rows = 'min PPV'\n",
    "y = 'F1 score'\n",
    "hue = 'title'\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(ncols=3, nrows=3, figsize=(12, 9))\n",
    "\n",
    "for i, min_precision in enumerate(min_precisions):\n",
    "    for j, prevalence in enumerate(prevalences):\n",
    "        \n",
    "        # select data:\n",
    "        df_ = df_selected[\n",
    "            (df_selected['Prevalence'] == prevalence) & \n",
    "            (df_selected['min PPV'] == min_precision)\n",
    "        ]\n",
    "        \n",
    "        # plot\n",
    "        sns.pointplot(df_, x=x, y=y, hue=hue, ax=axes[i, j], palette='deep', ms=5, hue_order=titles)\n",
    "\n",
    "        # set titles and labels\n",
    "        axes[i, j].set_title(f\"Prevalence: {prevalence}\\nMax FP:TP ratio: {min_precision:.2f}\")\n",
    "        axes[i, j].set_ylabel('F1 score')\n",
    "        axes[i, j].set_xlabel('Recordings')\n",
    "        axes[i, j].grid(True)\n",
    "        \n",
    "        # remove legends to avoid duplication\n",
    "        axes[i, j].legend().remove()\n",
    "\n",
    "axes[0, 2].legend(title=hue, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot \n",
    "\n",
    "\n",
    "\n",
    "# select data:\n",
    "# df_selected[df_selected['title'] == 'NT1 detector\\nPSG - Stanford test - 1 rec']\n",
    "x = 'Recordings (n)'\n",
    "cols = 'Prevalence'\n",
    "rows = 'min PPV'\n",
    "y = 'Sensitivity'\n",
    "hue = 'title'\n",
    "yy= 'FP:TP' # bar plot\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(ncols=3, nrows=3, figsize=(24, 24))\n",
    "\n",
    "for i, min_precision in enumerate(min_precisions):\n",
    "    for j, prevalence in enumerate(prevalences):\n",
    "        \n",
    "        # select data:\n",
    "        df_ = df_selected[\n",
    "            (df_selected['Prevalence'] == prevalence) & \n",
    "            (df_selected['min PPV'] == min_precision)\n",
    "        ]\n",
    "        \n",
    "        # plot\n",
    "        sns.pointplot(df_, x=x, y=y, hue=hue, ax=axes[i, j], palette='deep', ms=5, hue_order=titles)\n",
    "\n",
    "        # \n",
    "        ax2 = axes[i, j].twinx()\n",
    "\n",
    "        # plot bar plot on secondary y-axis\n",
    "        sns.barplot(data=df_, x=x, y=yy, hue=hue, ax=ax2, palette='deep', alpha=0.5, hue_order=titles)\n",
    "        \n",
    "        # set titles and labels\n",
    "        axes[i, j].set_title(f\"Prevalence: {prevalence}\\nMax FP:TP ratio: {min_precision}\")\n",
    "        axes[i, j].set_ylabel('Sensitivity')\n",
    "        axes[i, j].set_xlabel('Recordings')\n",
    "        axes[i, j].grid(True)\n",
    "        \n",
    "        # remove legends to avoid duplication\n",
    "        axes[i, j].legend().remove()\n",
    "        ax2.legend().remove()\n",
    "\n",
    "axes[0, 2].legend(title=hue, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.legend(title=hue, bbox_to_anchor=(1.05, 0.8), loc='upper left')\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nt1-wearable-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
