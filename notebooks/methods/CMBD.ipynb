{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMBD on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_path = r\"../src\"\n",
    "module_path_lib = r\"../lib\"\n",
    "sys.oath.append(module_path)\n",
    "sys.oath.append(module_path_lib)\n",
    "\n",
    "\n",
    "import CMBD.ConwayMaxwellBinomial as cmb\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_pmf_cdf(dist, xs):\n",
    "    \"\"\"Return PMF and CDF arrays for the given COM-B distribution over xs.\"\"\"\n",
    "    pmf = np.array([dist.pmf(k) for k in xs], dtype=float)\n",
    "    pmf = pmf / pmf.sum() # guard against tiny drift\n",
    "    cdf = np.cumsum(pmf)\n",
    "    return pmf, cdf\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    {'Dx': 'control', 'method': 'soremps', 'dataset': 'NSRR', 'nights': 2, 'outcomes': [0]*4580 + [1]*(72+76) + [2]*4},\n",
    "    {'Dx': 'control', 'method': 'multi', 'dataset': 'NSRR', 'nights': 2, 'outcomes': [0]*4625 + [1]*(59+44) + [2]*4},\n",
    "\n",
    "    {'Dx': 'NT1', 'method': 'soremps', 'dataset': 'TAK-all', 'nights': 2, 'outcomes': [0]*16 + [1]*(3+4) + [2]*5},\n",
    "    {'Dx': 'NT1', 'method': 'multi', 'dataset': 'TAK-all', 'nights': 2, 'outcomes': [0]*13 + [1]*6 + [2]*8},\n",
    "\n",
    "    {'Dx': 'NT1', 'method': 'soremps', 'dataset': 'comb', 'nights': 2, 'outcomes': [0]*43 + [1]*(52+19) + [2]*37},\n",
    "    {'Dx': 'NT1', 'method': 'multi', 'dataset': 'comb', 'nights': 2, 'outcomes': [0]*38 + [1]*(20+43) + [2]*50},\n",
    "\n",
    "    # Trying new approaches\n",
    "    {'Dx': 'NT1', 'method': 'multi', 'dataset': 'comb', 'nights': 3, 'outcomes': [0]*5 + [1]*6 + [2]*3 + [3]*4},\n",
    "    {'Dx': 'NT1', 'method': 'multi', 'dataset': 'comb', 'nights': 2, 'outcomes': [0]*9 + [1]*9 + [2]*12},\n",
    "    \n",
    "    #{'Dx': 'NT1', 'method': 'MSLT', 'dataset': 'MSLT', 'nights': 2, 'outcomes': [0]*10 + [1]*20 + [2]*47},\n",
    "]\n",
    "\n",
    "approach3es_1 = [\n",
    "    #{'name': \"SOREMP\", \"Control\": (0.0287044, 0.12888857), \"NT1\": (0.35857011, -0.35)},\n",
    "    #{'name': \"MULTI\", \"Control\": (0.02856839, -0.40111661), \"NT1\": (0.4396078,  -0.44)},\n",
    "    #{'name': \"SOREMP_1\", \"Control\": (0.02856839, -0.40111661), \"NT1\": (0.48, 0.83)},\n",
    "    #{'name': \"MULTI_1\", \"Control\": (0.02856839, -0.40111661), \"NT1\": (0.53, 0.53)},\n",
    "    \n",
    "    {'name': 'MULTI_2', 'Control': (0.02856839, -0.40111661), 'NT1': (0.458, 0.065)},\n",
    "    {'name': 'MULTI_3', 'Control': (0.02856839, -0.40111661), 'NT1': (0.537, -0.228)},\n",
    "    # {'name': 'MSLT', 'Control': (0.02856839, -0.40111661), 'NT1': (0.684, -0.116)},\n",
    "\n",
    "]\n",
    "\n",
    "approaches_2 = [\n",
    "    {\n",
    "        'name': 'Multi-feature',\n",
    "        'datasets': [\n",
    "            {'Dx': 'control', 'method': 'multi', 'dataset': 'NSRR', 'nights': 2, 'outcomes': [0]*4601 + [1]*(122) + [2]*9},\n",
    "            #{'Dx': 'NT1', 'method': 'multi', 'dataset': 'comb', 'nights': 3, 'outcomes': [0]*5 + [1]*6 + [2]*3 + [3]*4},\n",
    "            {'Dx': 'NT1', 'method': 'multi', 'dataset': 'comb', 'nights': 2, 'outcomes': [0]*9 + [1]*9 + [2]*12} # + [3]*4},\n",
    "        ]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'Multi-feature - 3 nights',\n",
    "        'datasets': [\n",
    "            {'Dx': 'control', 'method': 'multi', 'dataset': 'NSRR', 'nights': 2, 'outcomes': [0]*4601 + [1]*(122) + [2]*9},\n",
    "            {'Dx': 'NT1', 'method': 'multi', 'dataset': 'comb', 'nights': 3, 'outcomes': [0]*6 + [1]*6 + [2]*2 + [3]*4},\n",
    "        ]\n",
    "    }, \n",
    "    {\n",
    "        'name': 'SOREMP',\n",
    "        'datasets': [\n",
    "            {'Dx': 'control', 'method': 'soremps', 'dataset': 'NSRR', 'nights': 2, 'outcomes': [0]*4580 + [1]*(72+76) + [2]*4},\n",
    "            {'Dx': 'NT1', 'method': 'soremps', 'dataset': 'TAK-all', 'nights': 2, 'outcomes': [0]*14 + [1]*(11) + [2]*5},\n",
    "        ]\n",
    "    }, \n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nt1-wearable-sim/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400000, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "approach",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dx",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_recs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_pos_recs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cc4a25cb-5d02-47c6-b0cd-45c337826c02",
       "rows": [
        [
         "0",
         "Multi-feature",
         "control",
         "multi",
         "NSRR",
         "1",
         "0"
        ],
        [
         "1",
         "Multi-feature",
         "control",
         "multi",
         "NSRR",
         "1",
         "0"
        ],
        [
         "2",
         "Multi-feature",
         "control",
         "multi",
         "NSRR",
         "1",
         "0"
        ],
        [
         "3",
         "Multi-feature",
         "control",
         "multi",
         "NSRR",
         "1",
         "0"
        ],
        [
         "4",
         "Multi-feature",
         "control",
         "multi",
         "NSRR",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>Dx</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_recs</th>\n",
       "      <th>n_pos_recs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>control</td>\n",
       "      <td>multi</td>\n",
       "      <td>NSRR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>control</td>\n",
       "      <td>multi</td>\n",
       "      <td>NSRR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>control</td>\n",
       "      <td>multi</td>\n",
       "      <td>NSRR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>control</td>\n",
       "      <td>multi</td>\n",
       "      <td>NSRR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi-feature</td>\n",
       "      <td>control</td>\n",
       "      <td>multi</td>\n",
       "      <td>NSRR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        approach       Dx method dataset  n_recs  n_pos_recs\n",
       "0  Multi-feature  control  multi    NSRR       1           0\n",
       "1  Multi-feature  control  multi    NSRR       1           0\n",
       "2  Multi-feature  control  multi    NSRR       1           0\n",
       "3  Multi-feature  control  multi    NSRR       1           0\n",
       "4  Multi-feature  control  multi    NSRR       1           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# parameters\n",
    "recordings = 14\n",
    "df_1 = pd.DataFrame()\n",
    "realizations = 100000\n",
    "\n",
    "for approach in approaches_2:\n",
    "    for dataset in approach['datasets']:\n",
    "        # estimate parameters\n",
    "        p_est, nu_est = cmb.estimateParams(dataset.get('nights'), np.asarray(dataset.get('outcomes')))\n",
    "\n",
    "        for recording in range(1, recordings+1):\n",
    "            cmbd_dist = cmb.ConwayMaxwellBinomial(p_est,  nu_est,  recording) # Build COM-B distribution\n",
    "            samples = cmbd_dist.rvs(size=realizations).tolist() # Sample from distribution\n",
    "            #pmf, cdf = exact_pmf_cdf(dist_con, n_pos_recs)\n",
    "        \n",
    "            # append to dataframe\n",
    "            df_new = pd.DataFrame.from_dict({\n",
    "                'approach': approach['name'],\n",
    "                'Dx': dataset.get('Dx'),\n",
    "                'method': dataset.get('method'),\n",
    "                'dataset': dataset.get('dataset'),\n",
    "                'n_recs': recording, \n",
    "                'n_pos_recs': samples,\n",
    "            })\n",
    "            df_1 = pd.concat([df_1, df_new], ignore_index=True)\n",
    "            \n",
    "print(df_1.shape)\n",
    "df_1.head()\n",
    "# df_1[['Dx', 'n_pos_recs']].value_counts().unstack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "x = 'n_pos_recs'\n",
    "n_recs_all = [5, 14]\n",
    "#kwargs = {'bins': range(0, 2)} if len(df_1[x].unique()) == 1 else {'binwidth': 1}\n",
    "\n",
    "for approach in ['Multi-feature', 'SOREMP']:\n",
    "    for i, n_recs in enumerate(n_recs_all):\n",
    "    \n",
    "        # filter data\n",
    "        df_ = df_1.query(\"(approach == @approach) & (n_recs == @n_recs)\").copy()\n",
    "        \n",
    "        # figure\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4.5, 3.5))\n",
    "\n",
    "        sns.histplot(\n",
    "            data=df_,\n",
    "            x=x,\n",
    "            hue='Dx',\n",
    "            hue_order=['control', 'NT1'],\n",
    "            ax=ax,\n",
    "            stat='probability',  # normalize\n",
    "            common_norm=False,   # don't normalize across all hue groups\n",
    "            multiple='layer',    # side-by-side bars like countplot\n",
    "            #shrink=0.95,          # optional: shrink bar width for spacing\n",
    "            discrete=True        # ensure bars don't overlap if feature is discrete\n",
    "            #**kwargs\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Number of Positive Nights\")\n",
    "    \n",
    "        ax.set_ylabel(\"PMF (Probability)\")\n",
    "        ax.set_title(f\"Distributions of Positive Nights (n={n_recs})\")\n",
    "        ax.set_ylim(0, 1.01)\n",
    "        # ax.grid(True, alpha=0.3)\n",
    "        ax.grid(True, which='major', axis='both', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "        # xticks\n",
    "        max_ticks = 8\n",
    "        xticks = np.linspace(0, n_recs, num=min(max_ticks, n_recs+1), dtype=int)\n",
    "        ax.set_xticks(xticks)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        sns.ecdfplot(\n",
    "        data=df_,\n",
    "        x='n_pos_recs',\n",
    "        hue='Dx',\n",
    "        hue_order=['control', 'NT1'],\n",
    "        ax=ax2,\n",
    "        palette='dark'\n",
    "        )\n",
    "        \n",
    "        ax2.set_ylabel(\"CDF (Cumulative Probability)\")\n",
    "        ax2.set_ylim(0, 1.01)\n",
    "        ax2.grid(False)\n",
    "        \n",
    "        # Legends: keep only one combined legend on the right-most panel\n",
    "        leg1 = ax.get_legend()\n",
    "        if leg1:\n",
    "            if i == len(n_recs_all) - 1:\n",
    "                leg1.set_title(None)\n",
    "                leg1.set_loc(\"center right\")\n",
    "            else:\n",
    "                leg1.remove()\n",
    "\n",
    "        leg2 = ax2.get_legend()\n",
    "        if leg2:\n",
    "            leg2.remove()\n",
    "\n",
    "        plt.tight_layout() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred, prevalence=1/1024):\n",
    "    tp = round(((y_pred == 1) & (y_true == 1)).sum() * prevalence)\n",
    "    tn = round(((y_pred == 0) & (y_true == 0)).sum() * (1 - prevalence))\n",
    "    fp = round(((y_pred == 1) & (y_true == 0)).sum() * (1 - prevalence))\n",
    "    fn = round(((y_pred == 0) & (y_true == 1)).sum() * prevalence)\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def compute_metrics(y_true, y_pred, prevalence):\n",
    "\n",
    "    tp, tn, fp, fn = compute_confusion_matrix(y_true=y_true, y_pred=y_pred, prevalence=prevalence)\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "    fp_tp_ratio = fp / tp if tp > 0 else np.inf\n",
    "    f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else np.nan\n",
    "    \n",
    "    return {'Sensitivity': sensitivity, 'Specificity': specificity, 'PPV': ppv, 'FP:TP': fp_tp_ratio, 'F1 score': f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m             p_bin = (df_[\u001b[33m'\u001b[39m\u001b[33mn_pos_recs\u001b[39m\u001b[33m'\u001b[39m].values >= thresh).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     17\u001b[39m             \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[32m     18\u001b[39m             metrics.append({\n\u001b[32m     19\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mapproach\u001b[39m\u001b[33m'\u001b[39m: approach,\n\u001b[32m     20\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mRecordings (n)\u001b[39m\u001b[33m'\u001b[39m: n_rec,\n\u001b[32m     21\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mMin. required positive (n)\u001b[39m\u001b[33m'\u001b[39m: thresh,\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m                 **\u001b[43mcompute_metrics\u001b[49m(y_true=y, y_pred=p_bin, prevalence=prevalence)\n\u001b[32m     23\u001b[39m             })\n\u001b[32m     25\u001b[39m df_metrics = pd.DataFrame(metrics)\n\u001b[32m     26\u001b[39m df_metrics.head(\u001b[32m28\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'compute_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "prevalence=1/2048  # TODO - update prevalence\n",
    "thresholds = [1, 2, 3, 4, 5]\n",
    "\n",
    "metrics = []\n",
    "for approach in ['Multi-feature', 'SOREMP']:\n",
    "    for n_rec in range(1, recordings+1):\n",
    "        # filter data\n",
    "        df_ = df_1.query(\"(approach == @approach) & (n_recs == @n_rec)\").copy()\n",
    "        y = df_['Dx'].map({'control': 0, 'NT1': 1}).values\n",
    "        \n",
    "        for thresh in thresholds:\n",
    "            \n",
    "            # apply threshold\n",
    "            p_bin = (df_['n_pos_recs'].values >= thresh).astype(int)\n",
    "            \n",
    "            # compute metrics\n",
    "            metrics.append({\n",
    "                'approach': approach,\n",
    "                'Recordings (n)': n_rec,\n",
    "                'Min. required positive (n)': thresh,\n",
    "                **compute_metrics(y_true=y, y_pred=p_bin, prevalence=prevalence)\n",
    "            })\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.head(28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for approach in ['Multi-feature', 'SOREMP']:\n",
    "\n",
    "    df_ = df_metrics.query(\"approach == @approach\").copy()\n",
    "\n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(7, 3.5))\n",
    "\n",
    "    # Sensitivity plot\n",
    "    sns.pointplot(data=df_, hue='Min. required positive (n)', y='Sensitivity', x='Recordings (n)', palette='deep', ax=axes[0], markers='o', ms=4, lw=1)\n",
    "    axes[0].set_title('Sensitivity')\n",
    "    axes[0].set_ylabel('Sensitivity')\n",
    "    axes[0].grid(True, alpha=0.25)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    axes[0].set_xlim([-1, recordings])\n",
    "    axes[0].legend().remove()\n",
    "\n",
    "    # FP:TP Ratio plot\n",
    "    sns.pointplot(data=df_, hue='Min. required positive (n)', y='FP:TP', x='Recordings (n)', palette='deep', ax=axes[1], markers='o', ms=4, lw=1)\n",
    "    axes[1].set_title('FP:TP ratio')\n",
    "    axes[1].set_ylabel('FP:TP ratio')\n",
    "    axes[1].grid(True, alpha=0.25)\n",
    "    # axes[1].axhline(y=max_FPTP, color='black', linestyle='--', label='Max FP:TP')\n",
    "\n",
    "    ticks = [0.01, 0.1, 0.5, 2, 8, 32,  128,  512, 2048]\n",
    "    axes[1].set_yscale('symlog', base=2, linthresh=0.1)\n",
    "    axes[1].set_ylim([0, 2e3])\n",
    "    axes[1].set_xlim([-1, recordings])\n",
    "    axes[1].set_yticks(ticks)\n",
    "    axes[1].set_yticklabels([f'{tick:.2f}' if tick < 1 else f'{tick}' for tick in ticks])\n",
    "    axes[1].legend().remove()\n",
    "    axes[1].axhline(0.5, ls='--', color='k')\n",
    "    axes[1].legend(title='Min. required\\npositive (n)', loc='upper left', ncols=2, fontsize=8)\n",
    "\n",
    "    # F1 score plot\n",
    "    # sns.pointplot(data=df_, hue='Min. required positive (n)', y='F1 score', x='Recordings (n)', palette='deep', ax=axes[2], markers='o', ms=4, lw=1)\n",
    "    # # axes[2].set_title(f'F1 score (FP:TP < {max_FPTP:.1f})')\n",
    "    # axes[2].set_ylabel('F1 score')\n",
    "    # axes[2].grid(True, alpha=0.25)\n",
    "    # axes[2].set_ylim([0, 1])\n",
    "    # axes[2].set_xlim([-1, recordings])\n",
    "    # axes[2].legend().remove()\n",
    "    # axes[2].legend(title='Min. required positive (n)', loc='upper left', ncols=2, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nt1-wearable-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
