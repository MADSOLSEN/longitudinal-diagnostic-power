{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tqh7876/Library/CloudStorage/OneDrive-Takeda/ActiveProjects/WearableSimulations/code/quantitative-sciences-nt1-detection-wearable-simulation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "module_path = r\"../src\"\n",
    "sys.oath.append(module_path)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('path/to/dataframe.csv', low_memory=False)\n",
    "df_tr = df.query(\"Group_wearable == 'train'\").copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20867 entries, 0 to 20866\n",
      "Data columns (total 37 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Cohort                     20867 non-null  object \n",
      " 1   UNI-ID                     20867 non-null  object \n",
      " 2   Subject                    20867 non-null  object \n",
      " 3   Group_wearable             20867 non-null  object \n",
      " 4   Dx                         20867 non-null  object \n",
      " 5   age                        20662 non-null  float64\n",
      " 6   sex                        20675 non-null  object \n",
      " 7   visit_number               20867 non-null  int64  \n",
      " 8   n_visits_by_subject        20867 non-null  int64  \n",
      " 9   sleep_latency              20867 non-null  float64\n",
      " 10  total_sleep_time           20867 non-null  float64\n",
      " 11  sleep_efficiency           20867 non-null  float64\n",
      " 12  wake_after_sleep_onset     20867 non-null  float64\n",
      " 13  wake_percentage            20867 non-null  float64\n",
      " 14  n1_percentage              20867 non-null  float64\n",
      " 15  n2_percentage              20867 non-null  float64\n",
      " 16  n3_percentage              20867 non-null  float64\n",
      " 17  rem_percentage             20867 non-null  float64\n",
      " 18  rem_latency                20867 non-null  float64\n",
      " 19  soremp                     20867 non-null  bool   \n",
      " 20  rCountR                    20867 non-null  float64\n",
      " 21  soremC                     20867 non-null  float64\n",
      " 22  wCum                       20867 non-null  float64\n",
      " 23  wBout                      20867 non-null  float64\n",
      " 24  nFrag                      20867 non-null  float64\n",
      " 25  five_n1w_to_two_r          20867 non-null  float64\n",
      " 26  rem_in_first_30_min        20861 non-null  float64\n",
      " 27  rem_in_first_60_min        20861 non-null  float64\n",
      " 28  rem_in_first_120_min       20861 non-null  float64\n",
      " 29  Dx_idx                     20867 non-null  int64  \n",
      " 30  p-bin_five_n1w_to_two_r=0  20867 non-null  bool   \n",
      " 31  p-bin_five_n1w_to_two_r=1  20867 non-null  bool   \n",
      " 32  p-bin_five_n1w_to_two_r=2  20867 non-null  bool   \n",
      " 33  p-bin_five_n1w_to_two_r=3  20867 non-null  bool   \n",
      " 34  p-bin_five_n1w_to_two_r=4  20867 non-null  bool   \n",
      " 35  p-bin_multi-condition      20867 non-null  bool   \n",
      " 36  p-bin_best-condition       20867 non-null  bool   \n",
      "dtypes: bool(8), float64(20), int64(3), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Thresholds\n",
    "# TODO - update the thresholds to reflect what you found in the threshold tuning notebook!\n",
    "data = [\n",
    "    {\"five_n1w_to_two_r\": 0, \"rem_latency\": 1,  \"recall_at_99.5%_specificity\": 0.4645},\n",
    "    {\"five_n1w_to_two_r\": 1, \"rem_latency\": 8, \"recall_at_99.5%_specificity\": 0.5213},\n",
    "    {\"five_n1w_to_two_r\": 2, \"rem_latency\": 24, \"recall_at_99.5%_specificity\": 0.4362},\n",
    "    {\"five_n1w_to_two_r\": 3, \"rem_latency\": 42, \"recall_at_99.5%_specificity\": 0.3404},\n",
    "    {\"five_n1w_to_two_r\": 4, \"rem_latency\": 82, \"recall_at_99.5%_specificity\": 0.2695},\n",
    "    {\"five_n1w_to_two_r\": 5, \"rem_latency\": 10000, \"recall_at_99.5%_specificity\": 0.1879}\n",
    "]\n",
    "data = [\n",
    "    {\"five_n1w_to_two_r\": 0, \"rem_latency\": 1,  \"recall_at_99.5%_specificity\": 0.4645},\n",
    "    {\"five_n1w_to_two_r\": 1, \"rem_latency\": 7, \"recall_at_99.5%_specificity\": 0.5213},\n",
    "    {\"five_n1w_to_two_r\": 2, \"rem_latency\": 22, \"recall_at_99.5%_specificity\": 0.4362},\n",
    "    {\"five_n1w_to_two_r\": 3, \"rem_latency\": 41, \"recall_at_99.5%_specificity\": 0.3404},\n",
    "    {\"five_n1w_to_two_r\": 4, \"rem_latency\": 80, \"recall_at_99.5%_specificity\": 0.2695},\n",
    "    {\"five_n1w_to_two_r\": 5, \"rem_latency\": 10000, \"recall_at_99.5%_specificity\": 0.1879}\n",
    "]\n",
    "\n",
    "data = [\n",
    "    {\"five_n1w_to_two_r\": 0, \"rem_latency\": 1,  \"recall_at_99.5%_specificity\": 0.4645},\n",
    "    {\"five_n1w_to_two_r\": 1, \"rem_latency\": 7, \"recall_at_99.5%_specificity\": 0.5213},\n",
    "    {\"five_n1w_to_two_r\": 2, \"rem_latency\": 22, \"recall_at_99.5%_specificity\": 0.4362},\n",
    "    {\"five_n1w_to_two_r\": 3, \"rem_latency\": 40, \"recall_at_99.5%_specificity\": 0.3404},\n",
    "    {\"five_n1w_to_two_r\": 4, \"rem_latency\": 1e6, \"recall_at_99.5%_specificity\": 0.2695},\n",
    "    # {\"five_n1w_to_two_r\": 5, \"rem_latency\": 10000, \"recall_at_99.5%_specificity\": 0.1879}\n",
    "]\n",
    "\n",
    "# data = [\n",
    "#     {\"five_n1w_to_two_r\": 0, \"rem_latency\": 0,  \"recall_at_99.5%_specificity\": 0.4645},\n",
    "#     {\"five_n1w_to_two_r\": 1, \"rem_latency\": 15, \"recall_at_99.5%_specificity\": 0.5213},\n",
    "#     {\"five_n1w_to_two_r\": 2, \"rem_latency\": 30, \"recall_at_99.5%_specificity\": 0.4362},\n",
    "#     {\"five_n1w_to_two_r\": 3, \"rem_latency\": 60, \"recall_at_99.5%_specificity\": 0.3404},\n",
    "#     {\"five_n1w_to_two_r\": 4, \"rem_latency\": 1e6, \"recall_at_99.5%_specificity\": 0.2695},\n",
    "#     #{\"five_n1w_to_two_r\": 5, \"rem_latency\": 10000, \"recall_at_99.5%_specificity\": 0.1879}\n",
    "#]\n",
    "\n",
    "df_bests = pd.DataFrame(data)\n",
    "\n",
    "# parameters\n",
    "outer = 'five_n1w_to_two_r'\n",
    "inner = 'rem_latency'\n",
    "\n",
    "# save prediction\n",
    "for i, row in df_bests.iterrows():\n",
    "    df_best = row.to_dict()\n",
    "    outer_best = int(df_best[outer])\n",
    "    inner_best = int(df_best[inner])\n",
    "\n",
    "    # apply threshold\n",
    "    df[f\"p-bin_{outer}={outer_best}\"] = (df[outer] >= outer_best) & (df[inner] <= inner_best)\n",
    "\n",
    "\n",
    "# Combined conditions\n",
    "# -------------------\n",
    "multi_condition = [\n",
    "    'p-bin_five_n1w_to_two_r=0', \n",
    "    'p-bin_five_n1w_to_two_r=1', \n",
    "    'p-bin_five_n1w_to_two_r=2',\n",
    "    'p-bin_five_n1w_to_two_r=3',\n",
    "    'p-bin_five_n1w_to_two_r=4',\n",
    "    #'p-bin_five_n1w_to_two_r=5'\n",
    "]\n",
    "best_condtition = ['p-bin_five_n1w_to_two_r=1']\n",
    "\n",
    "# Apply row-wise logical OR across the selected columns\n",
    "df['p-bin_multi-condition'] = df[multi_condition].any(axis=1)\n",
    "df['p-bin_best-condition'] = df[best_condtition].any(axis=1)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dicts\n",
    "pred_dicts = [\n",
    "    {\n",
    "        'feature': 'soremp',\n",
    "        'display': 'SOREMP\\n(REML<15 min)',\n",
    "    },\n",
    "    #{\n",
    "    #    'feature': 'p-bin_best-condition',\n",
    "    #    'display': 'Best condition - REML & d-REM\\n(Christensen et al. 2015)\\nmax recall @ minSpe=99.5%',\n",
    "    #},\n",
    "    {\n",
    "        'feature': 'p-bin_multi-condition',\n",
    "        'display': 'Multiple conditions - REML & d-REM\\n(Christensen et al. 2015)\\nmax recall @ minSpe=99.5',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from vis.confusion_matrix import plot_cm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# selected cohorts\n",
    "#cohorts_incl = ['wsc', 'stages', 'cfs', 'chat', 'mesa', 'mros', 'shhs', 'cnc', 'dhc', 'fhc', 'ihc', 'khc', 'ssc', '994-0001', '994-1501']\n",
    "cohorts_incl = ['wsc', 'stages', 'cfs', 'chat', 'mesa', 'mros', 'shhs', 'cnc', 'dhc', 'fhc', 'ihc', 'khc', 'ssc', '861-2001']\n",
    "df_selected = df[df['Cohort'].isin(cohorts_incl)].copy()\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "for split in [['train'], ['test'], ['test_multivisits', 'test']]:\n",
    "    for pred_dict in pred_dicts:\n",
    "    \n",
    "        # select data\n",
    "        df_split = df_selected[df_selected['Group_wearable'].isin(split) & (df_selected['visit_number'] == 1)]\n",
    "        # ].query(f\"(Group_wearable in @split) & (visit_number == 1))\").copy()\n",
    "\n",
    "        # extract features and thresholds\n",
    "        y_true = df_split['Dx_idx'].values\n",
    "        y_pred = np.array(df_split[pred_dict['feature']].values, dtype=float)\n",
    "        \n",
    "        # remove NANs\n",
    "        nan_mask = np.isnan(y_pred)\n",
    "        y_true_valid = y_true[~nan_mask]\n",
    "        y_pred_valid = y_pred[~nan_mask]\n",
    "        \n",
    "        # print\n",
    "        # print(f\"{split} {pred_dict['display']}: {y_pred_bin.sum()} of {y_pred_bin.shape[0]}\")\n",
    "\n",
    "        # build cm\n",
    "        cm = confusion_matrix(y_true_valid, y_pred_valid)\n",
    "        \n",
    "        # plot confusion matrix\n",
    "        plot_cm(cm, events=['Con', 'NT1'], title=f\"{pred_dict['display']}\", marginals=True, decimals=0, figsize=(2., 2.), fontsize=8)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('Dx', 'Group_wearable')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3a1d7d2d-cb32-4b63-9dbb-8ec789e92df3",
       "rows": [
        [
         "('NT1', 'test')",
         "123"
        ],
        [
         "('NT1', 'test_multivisits')",
         "56"
        ],
        [
         "('NT1', 'train')",
         "99"
        ],
        [
         "('control', 'test')",
         "170"
        ],
        [
         "('control', 'test_multivisits')",
         "9839"
        ],
        [
         "('control', 'train')",
         "10526"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "Dx       Group_wearable  \n",
       "NT1      test                  123\n",
       "         test_multivisits       56\n",
       "         train                  99\n",
       "control  test                  170\n",
       "         test_multivisits     9839\n",
       "         train               10526\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) plot confusion matrix (results)\n",
    "# 2) plot test-retest results - maybe just as a table ?! \n",
    "df_selected[['Dx', 'Group_wearable']].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from vis.confusion_matrix import plot_cm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Multi-night conditinoal data\n",
    "datasets = ['861-2001', '994-0001', '994-1501']\n",
    "datasets = ['861-2001', '994-1501']\n",
    "#datasets = ['994-0001', '994-1501']\n",
    "#groups = ['train', 'test', 'test_multivisit']\n",
    "groups = ['test_multivisits']\n",
    "Dxs = ['control', 'NT1']\n",
    "\n",
    "\n",
    "for pred_dict in pred_dicts:\n",
    "    for group in groups:\n",
    "        for Dx in Dxs: \n",
    "            \n",
    "            # pivot\n",
    "            # df_ = df.query(\"(Group_wearable == @group) & (Dx == @Dx) & (dataset in @datasets)\")\n",
    "            df_ = df.query(\"(Group_wearable == @group) & (Dx == @Dx)\")\n",
    "            df_pivot = df_.pivot(index=['Subject', 'Dx'], columns='visit_number', values=pred_dict['feature'])\n",
    "            \n",
    "            df_pivot = df_pivot.reset_index()\n",
    "            \n",
    "            # get data\n",
    "            y_1 = np.bool(df_pivot[1].values)\n",
    "            y_2 = np.bool(df_pivot[2].values)\n",
    "            # y_3 = np.bool(df_pivot['PSG03'].values)\n",
    "\n",
    "            # build cm\n",
    "            cm = confusion_matrix(y_1, y_2)\n",
    "            \n",
    "            # plot confusion matrix\n",
    "            title=f\"{Dx} - 2 day\\n{pred_dict['display']}\"\n",
    "\n",
    "            plot_cm(cm, events=['-', '+'],\n",
    "                    marginals=False, decimals=0, decimals_marg=3,\n",
    "                    title=title, xlabel='Test 2', ylabel='Test 1', \n",
    "                    figsize=(2.5, 2.5), fontsize=9)\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nt1-wearable-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
