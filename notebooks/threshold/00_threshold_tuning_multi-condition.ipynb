{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_path = r\"../src\"\n",
    "sys.oath.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('path/to/spreadsheet.csv', low_memory=False)\n",
    "df_tr = df.query(\"Group_wearable == 'train'\").copy()\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual - at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "five_n1w_to_two_r",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "19e84200-2173-484c-bd55-15b76fd8c5f7",
       "rows": [
        [
         "0.0",
         "7818"
        ],
        [
         "1.0",
         "1755"
        ],
        [
         "2.0",
         "606"
        ],
        [
         "3.0",
         "210"
        ],
        [
         "4.0",
         "84"
        ],
        [
         "5.0",
         "28"
        ],
        [
         "6.0",
         "10"
        ],
        [
         "7.0",
         "6"
        ],
        [
         "9.0",
         "4"
        ],
        [
         "8.0",
         "2"
        ],
        [
         "11.0",
         "2"
        ],
        [
         "10.0",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "five_n1w_to_two_r\n",
       "0.0     7818\n",
       "1.0     1755\n",
       "2.0      606\n",
       "3.0      210\n",
       "4.0       84\n",
       "5.0       28\n",
       "6.0       10\n",
       "7.0        6\n",
       "9.0        4\n",
       "8.0        2\n",
       "11.0       2\n",
       "10.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - enforcing a 99.5 % specificity at higher dREMs we begin to lack control data - and the threshold begins to be very unrealiable.\n",
    "# if we were to bootstrap it, the threshold would vary a lot. How do we account for this?\n",
    "\n",
    "df_tr.loc[(df_tr['Dx'] == 'control'), 'five_n1w_to_two_r'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 4 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   metric                                244 non-null    object \n",
      " 1   direct REM (Christensen et al. 2015)  244 non-null    int64  \n",
      " 2   REM Latency (min)                     244 non-null    int64  \n",
      " 3   performance                           244 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 7.8+ KB\n"
     ]
    }
   ],
   "source": [
    "from evaluation.threshold_tuning import tune_threshold\n",
    "from utils import metrics_dict_array\n",
    "\n",
    "# metrics \n",
    "# metric_dict = {\n",
    "#     'metric': 'f1_score',\n",
    "#     'display': 'F1 Score',\n",
    "#     'save_friendly': 'F1_Score',\n",
    "#     'tuning_fun': None,\n",
    "# }\n",
    "# metric_dict = {\n",
    "#     'metric': '',\n",
    "#     'display': f'Recall (min Spe=98.%)',\n",
    "#     'save_friendly': 'maxRe-Sp98',\n",
    "#     'tuning_fun': metrics_dict_array['recall_min_spe_wrapper'](minimum_specificity=0.98),\n",
    "# }\n",
    "metric_dict = {\n",
    "    'metric': '',\n",
    "    'display': f'Recall (Spe=99.5%)',\n",
    "    'save_friendly': 'Re-Sp995',\n",
    "    'tuning_fun': metrics_dict_array['recall_min_spe_wrapper'](minimum_specificity=0.995),\n",
    "}\n",
    "\n",
    "# --- Feature and Metric Configuration ---\n",
    "feature_outer = {\n",
    "    'feature': 'five_n1w_to_two_r',\n",
    "    'display': 'direct REM (Christensen et al. 2015)',\n",
    "    'plot_type': 'histogram',\n",
    "    'bigger_than': True,\n",
    "    'tuning': True,\n",
    "    'ylim': (0, 4)\n",
    "}\n",
    "feature_inner = {\n",
    "    'feature': 'rem_latency',\n",
    "    'display': 'REM Latency (min)',\n",
    "    'plot_type': 'violin',\n",
    "    'bigger_than': False,\n",
    "    'tuning': True,\n",
    "    'ylim': (0, 60),\n",
    "    'stepsize': 1,\n",
    "}\n",
    "\n",
    "# outer feature threshold\n",
    "best = []\n",
    "results = []\n",
    "# source = 'pkl'\n",
    "\n",
    "for thr_outer in np.arange(feature_outer['ylim'][0], feature_outer['ylim'][1]): \n",
    "    \n",
    "    # Prepare inputs for tuning\n",
    "    y_true = df_tr['Dx_idx'].copy().values\n",
    "    y_scores = df_tr[feature_inner['feature']].copy().values\n",
    "    \n",
    "    # D-REM < thr_outer --> set REM latency to a million \n",
    "    outer_mask = (df_tr[feature_outer['feature']] < thr_outer).values\n",
    "    y_scores[outer_mask] = 1e6\n",
    "\n",
    "    # Tune threshold\n",
    "    tr_thr_best, tr_thr, tr_perf = tune_threshold(\n",
    "        y_true,\n",
    "        y_scores,\n",
    "        bigger_than=feature_inner['bigger_than'],\n",
    "        metric=metric_dict['metric'],\n",
    "        tuning_fun=metric_dict['tuning_fun'],\n",
    "        threshold_maximum=int(feature_inner['ylim'][1]),\n",
    "        threshold_minimum=max(0, int(feature_inner['ylim'][0])),\n",
    "        threshold_stepsize=feature_inner['stepsize'],\n",
    "        max_strategy='max'\n",
    "    )\n",
    "\n",
    "    for thr_inner, perf in zip(tr_thr, tr_perf):\n",
    "        results.append({\n",
    "            'metric': metric_dict['display'],\n",
    "            feature_outer['display']: thr_outer,\n",
    "            feature_inner['display']: thr_inner,\n",
    "            'performance': perf\n",
    "        })\n",
    "\n",
    "    # Set threshold to a million if it goes above threshold\n",
    "    tr_thr_best['threshold'] = 1e6 if tr_thr_best['threshold'] == feature_inner['ylim'][1] else tr_thr_best['threshold']\n",
    "\n",
    "    # save best performance\n",
    "    best.append({\n",
    "       'metric': metric_dict['display'],\n",
    "       feature_outer['display']: thr_outer, \n",
    "       **tr_thr_best\n",
    "    }) \n",
    "\n",
    "    # apply threshold\n",
    "    # df[f\"p-bin_{feature_outer['feature']}={thr_outer}\"] = df.apply(lambda x: (x[feature_outer['feature']] >= thr_outer) & (x[feature_inner['feature']] < tr_thr_best['threshold']), axis=1)\n",
    "    df[f\"p-bin_{feature_outer['feature']}={thr_outer}\"] = (df[feature_outer['feature']] >= thr_outer) & (df[feature_inner['feature']] < tr_thr_best['threshold'])\n",
    "\n",
    "df_bests = pd.DataFrame(best)\n",
    "df_metrics = pd.DataFrame(results)\n",
    "df_metrics.info()\n",
    "# df_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "direct REM (Christensen et al. 2015)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "threshold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "performance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d3e8b1e0-521f-4f38-9f6f-23e9108f862e",
       "rows": [
        [
         "0",
         "Recall (Spe=99.5%)",
         "0",
         "1",
         "1",
         "0.13131313131313133"
        ],
        [
         "1",
         "Recall (Spe=99.5%)",
         "1",
         "7",
         "7",
         "0.30303030303030304"
        ],
        [
         "2",
         "Recall (Spe=99.5%)",
         "2",
         "22",
         "22",
         "0.26262626262626265"
        ],
        [
         "3",
         "Recall (Spe=99.5%)",
         "3",
         "40",
         "40",
         "0.1717171717171717"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>direct REM (Christensen et al. 2015)</th>\n",
       "      <th>threshold</th>\n",
       "      <th>index</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recall (Spe=99.5%)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall (Spe=99.5%)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall (Spe=99.5%)</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.262626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall (Spe=99.5%)</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.171717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               metric  direct REM (Christensen et al. 2015)  threshold  index  \\\n",
       "0  Recall (Spe=99.5%)                                     0          1      1   \n",
       "1  Recall (Spe=99.5%)                                     1          7      7   \n",
       "2  Recall (Spe=99.5%)                                     2         22     22   \n",
       "3  Recall (Spe=99.5%)                                     3         40     40   \n",
       "\n",
       "   performance  \n",
       "0     0.131313  \n",
       "1     0.303030  \n",
       "2     0.262626  \n",
       "3     0.171717  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bests.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Ensure consistent naming\n",
    "outer_label = feature_outer['display']\n",
    "inner_label = feature_inner['display']\n",
    "\n",
    "plot_best = False\n",
    "plot_all_outer = False\n",
    "\n",
    "# ax = axes[c]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.7, 4))\n",
    "\n",
    "# Pivot for heatmap: rows = inner threshold, cols = outer threshold\n",
    "surface = df_metrics.pivot(index=inner_label, columns=outer_label, values='performance')\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(surface, cmap='viridis', vmin=0, vmax=df_bests['performance'].max(), cbar_kws={'label': 'Performance'}, ax=ax, annot_kws={\"size\": 8})\n",
    "\n",
    "# Titles and labels\n",
    "ax.collections[0].colorbar.set_label(metric_dict['display'])\n",
    "ax.set_xlabel(f\"Threshold\\n{feature_outer['display']}\")\n",
    "ax.set_ylabel(f\"Threshold\\n{feature_inner['display']}\")\n",
    "\n",
    "# Extract actual y-tick values from surface.index\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=6, integer=True))  # Adjust nbins as needed\n",
    "\n",
    "# Limit y-axis (inner threshold) ticks to avoid overcrowding\n",
    "y_tick_vals = surface.index.to_numpy()\n",
    "\n",
    "# Show every Nth tick (e.g., every 5th label)\n",
    "step = max(1, len(y_tick_vals) // 6)  # adjust \"6\" to control density\n",
    "ax.set_yticks(y_tick_vals[::step])\n",
    "ax.set_yticklabels([str(y) for y in y_tick_vals[::step]])\n",
    "\n",
    "for i, row in df_bests.iterrows():\n",
    "    df_best = row.to_dict()\n",
    "\n",
    "    best_outer = int(df_best[outer_label])\n",
    "    best_inner = int(df_best['threshold'])\n",
    "    best_perf = float(df_best['performance'])\n",
    "\n",
    "    try:\n",
    "        x_loc = surface.columns.get_loc(best_outer) + 0.5\n",
    "        y_loc = surface.index.get_loc(best_inner) + 5\n",
    "        \n",
    "        # Plot the best performance point\n",
    "        #ax.axhline(\n",
    "        #    y=y_loc, color=(1.0000, 0.4980, 0.0549), linestyle='-', linewidth=1.5, label='Best Inner Threshold'\n",
    "        #)\n",
    "        #ax.axvline(\n",
    "        #    x=x_loc, color=(1.0000, 0.4980, 0.0549), linestyle='-', linewidth=1.5, label='Best Outer Threshold'\n",
    "        #)\n",
    "\n",
    "        ax.text(\n",
    "            x=x_loc,\n",
    "            y=y_loc,\n",
    "            #s=f\"{best_perf:.2f}\",\n",
    "            s=f\"{best_inner}\",\n",
    "            color='white', # if best_perf < 0.40 else 'black',\n",
    "            ha='center', va='center',\n",
    "            fontsize=10,\n",
    "            fontweight='bold',\n",
    "            # bbox=dict(facecolor='red', edgecolor='none', boxstyle='round,pad=0.3')\n",
    "        )\n",
    "    except:\n",
    "        k = 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nt1-wearable-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
